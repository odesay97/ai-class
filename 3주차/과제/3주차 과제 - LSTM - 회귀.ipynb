{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6733fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean Squared Error (MSE): 0.0769\n",
    "Root Mean Squared Error (RMSE): 0.2773\n",
    "R² Score: 0.9936\n",
    "MAE: 0.063\n",
    "\n",
    "#  LSTM은 시간에 따른 데이터 추이를 가지기 때문에 반드시 입력값을 정렬해줘야함 -> 시간에 따라 변화하는 방향으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a43fc887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>I</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>I</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>I</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>I</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>1429</td>\n",
       "      <td>I</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2201</td>\n",
       "      <td>F</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.4060</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.0575</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>2209</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2108</td>\n",
       "      <td>M</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.1835</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.3910</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>F</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.8075</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "236    236   I   0.075     0.055   0.010        0.0020          0.0010   \n",
       "719    719   I   0.150     0.100   0.025        0.0150          0.0045   \n",
       "238    238   I   0.110     0.090   0.030        0.0080          0.0025   \n",
       "237    237   I   0.130     0.100   0.030        0.0130          0.0045   \n",
       "1429  1429   I   0.140     0.105   0.035        0.0140          0.0055   \n",
       "...    ...  ..     ...       ...     ...           ...             ...   \n",
       "2201  2201   F   0.645     0.490   0.215        1.4060          0.4265   \n",
       "294    294   M   0.600     0.495   0.195        1.0575          0.3840   \n",
       "2209  2209   F   0.550     0.465   0.180        1.2125          0.3245   \n",
       "2108  2108   M   0.665     0.535   0.225        2.1835          0.7535   \n",
       "480    480   F   0.700     0.585   0.185        1.8075          0.7055   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "236           0.0005        0.0015      0  \n",
       "719           0.0040        0.0050      1  \n",
       "238           0.0020        0.0030      2  \n",
       "237           0.0030        0.0040      2  \n",
       "1429          0.0025        0.0040      2  \n",
       "...              ...           ...    ...  \n",
       "2201          0.2285        0.5100     24  \n",
       "294           0.1900        0.3750     25  \n",
       "2209          0.2050        0.5250     26  \n",
       "2108          0.3910        0.8850     26  \n",
       "480           0.3215        0.4750     28  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from numpy import array\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 함수: 시퀀스를 샘플로 분할\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "def feature_eng(df):\n",
    "    \n",
    "#     # 특성 엔지니어링\n",
    "#     df['Length_to_Diameter'] = df['Length'] / df['Diameter']\n",
    "#     df['Weight_Ratio'] = df['Shucked_weight'] / df['Whole_weight']\n",
    "\n",
    "#     df['Water'] = df['Whole_weight'] - df['Shucked_weight'] - df['Viscera_weight'] - df['Shell_weight']\n",
    "#     df['new'] = df['Shell_weight']+df['Height']\n",
    "#     df['Length_Diameter_Product'] = df['Length'] * df['Diameter']\n",
    "#     df['Shell_Weight_Ratio'] = df['Shell_weight'] / df['Whole_weight']\n",
    "\n",
    "    # 부피와 밀도 계산 전에 0으로 나누는 것을 방지\n",
    "    df['Volume'] = df['Length'] * df['Height'] * df['Diameter']\n",
    "#     df['Density'] = df['Whole_weight'] / df['Volume']\n",
    "#     df.replace([np.inf, -np.inf], np.nan, inplace=True)  # 무한대 값 NaN으로 대체\n",
    "#     df.dropna(inplace=True)  # NaN 값 제거\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "url = 'https://raw.githubusercontent.com/MyungKyuYi/AI-class/main/abalone.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# 시계열 데이터를 만들기 위해 Rings를 기준으로 오름차순 정렬\n",
    "# Rings가 동일한 데이터일 경우 가장 Rings에 대해 영향이 큰 Shell_weight를 기준으로 재정렬\n",
    "data = data.sort_values(by=['Rings', 'Shell_weight'], ascending=[True, True])\n",
    "\n",
    "# 'Rings' 열을 0부터 시작하도록 조정\n",
    "data['Rings'] = data['Rings'] - 1\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af43c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Rings'를 예측 타겟으로 사용\n",
    "target = data['Rings'].values\n",
    "\n",
    "# 특성공학 \n",
    "data = feature_eng(data)\n",
    "\n",
    "\n",
    "# 특성 선택 및 데이터 스케일링\n",
    "features = data.drop(['Rings', 'Sex','id'], axis=1)  # 성별 제거\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 시계열 데이터 형식으로 변환 (예: 3개의 타임 스텝 사용)\n",
    "n_steps = 3\n",
    "X, y = split_sequence(target, n_steps)\n",
    "\n",
    "# LSTM 입력 형식에 맞게 데이터 차원 변경\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 데이터 분할 --> 훈련 및 검증까지 train 데이터로 할 것임\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 성능 평가를 위한 데이터셋 섞음\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=48)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03c62e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyeon\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer='l2'), input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, kernel_regularizer='l2'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93a27c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 81.1789 - val_loss: 64.8622 - learning_rate: 1.0000e-04\n",
      "Epoch 2/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.5923 - val_loss: 36.5511 - learning_rate: 1.0000e-04\n",
      "Epoch 3/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.0610 - val_loss: 20.2816 - learning_rate: 1.0000e-04\n",
      "Epoch 4/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3420 - val_loss: 14.5325 - learning_rate: 1.0000e-04\n",
      "Epoch 5/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.9539 - val_loss: 12.4855 - learning_rate: 1.0000e-04\n",
      "Epoch 6/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.9361 - val_loss: 11.5244 - learning_rate: 1.0000e-04\n",
      "Epoch 7/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.5142 - val_loss: 10.8896 - learning_rate: 1.0000e-04\n",
      "Epoch 8/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8860 - val_loss: 10.2665 - learning_rate: 1.0000e-04\n",
      "Epoch 9/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6773 - val_loss: 9.5807 - learning_rate: 1.0000e-04\n",
      "Epoch 10/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4940 - val_loss: 8.8879 - learning_rate: 1.0000e-04\n",
      "Epoch 11/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9063 - val_loss: 8.2356 - learning_rate: 1.0000e-04\n",
      "Epoch 12/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7152 - val_loss: 7.6601 - learning_rate: 1.0000e-04\n",
      "Epoch 13/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0541 - val_loss: 7.1689 - learning_rate: 1.0000e-04\n",
      "Epoch 14/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1673 - val_loss: 6.7295 - learning_rate: 1.0000e-04\n",
      "Epoch 15/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9419 - val_loss: 6.3618 - learning_rate: 1.0000e-04\n",
      "Epoch 16/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9227 - val_loss: 6.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 17/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9141 - val_loss: 5.7007 - learning_rate: 1.0000e-04\n",
      "Epoch 18/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3987 - val_loss: 5.4190 - learning_rate: 1.0000e-04\n",
      "Epoch 19/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9569 - val_loss: 5.1636 - learning_rate: 1.0000e-04\n",
      "Epoch 20/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8135 - val_loss: 4.9240 - learning_rate: 1.0000e-04\n",
      "Epoch 21/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7434 - val_loss: 4.7223 - learning_rate: 1.0000e-04\n",
      "Epoch 22/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7279 - val_loss: 4.4947 - learning_rate: 1.0000e-04\n",
      "Epoch 23/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6989 - val_loss: 4.2932 - learning_rate: 1.0000e-04\n",
      "Epoch 24/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0590 - val_loss: 4.1190 - learning_rate: 1.0000e-04\n",
      "Epoch 25/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2307 - val_loss: 3.9742 - learning_rate: 1.0000e-04\n",
      "Epoch 26/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8196 - val_loss: 3.8265 - learning_rate: 1.0000e-04\n",
      "Epoch 27/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9363 - val_loss: 3.6574 - learning_rate: 1.0000e-04\n",
      "Epoch 28/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6837 - val_loss: 3.5274 - learning_rate: 1.0000e-04\n",
      "Epoch 29/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3996 - val_loss: 3.3850 - learning_rate: 1.0000e-04\n",
      "Epoch 30/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2978 - val_loss: 3.2813 - learning_rate: 1.0000e-04\n",
      "Epoch 31/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4692 - val_loss: 3.1696 - learning_rate: 1.0000e-04\n",
      "Epoch 32/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1252 - val_loss: 3.0304 - learning_rate: 1.0000e-04\n",
      "Epoch 33/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8847 - val_loss: 2.9362 - learning_rate: 1.0000e-04\n",
      "Epoch 34/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1773 - val_loss: 2.8275 - learning_rate: 1.0000e-04\n",
      "Epoch 35/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6705 - val_loss: 2.7411 - learning_rate: 1.0000e-04\n",
      "Epoch 36/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9665 - val_loss: 2.6759 - learning_rate: 1.0000e-04\n",
      "Epoch 37/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7043 - val_loss: 2.5661 - learning_rate: 1.0000e-04\n",
      "Epoch 38/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8930 - val_loss: 2.4547 - learning_rate: 1.0000e-04\n",
      "Epoch 39/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0822 - val_loss: 2.3705 - learning_rate: 1.0000e-04\n",
      "Epoch 40/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5531 - val_loss: 2.2981 - learning_rate: 1.0000e-04\n",
      "Epoch 41/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7992 - val_loss: 2.2467 - learning_rate: 1.0000e-04\n",
      "Epoch 42/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5000 - val_loss: 2.1606 - learning_rate: 1.0000e-04\n",
      "Epoch 43/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7066 - val_loss: 2.0777 - learning_rate: 1.0000e-04\n",
      "Epoch 44/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3604 - val_loss: 2.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 45/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3953 - val_loss: 1.9472 - learning_rate: 1.0000e-04\n",
      "Epoch 46/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4142 - val_loss: 1.8722 - learning_rate: 1.0000e-04\n",
      "Epoch 47/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3008 - val_loss: 1.8183 - learning_rate: 1.0000e-04\n",
      "Epoch 48/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3421 - val_loss: 1.7557 - learning_rate: 1.0000e-04\n",
      "Epoch 49/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4023 - val_loss: 1.7032 - learning_rate: 1.0000e-04\n",
      "Epoch 50/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0619 - val_loss: 1.6495 - learning_rate: 1.0000e-04\n",
      "Epoch 51/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8489 - val_loss: 1.6051 - learning_rate: 1.0000e-04\n",
      "Epoch 52/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8895 - val_loss: 1.5539 - learning_rate: 1.0000e-04\n",
      "Epoch 53/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3266 - val_loss: 1.5033 - learning_rate: 1.0000e-04\n",
      "Epoch 54/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8716 - val_loss: 1.4816 - learning_rate: 1.0000e-04\n",
      "Epoch 55/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8347 - val_loss: 1.4050 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7804 - val_loss: 1.3617 - learning_rate: 1.0000e-04\n",
      "Epoch 57/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9104 - val_loss: 1.3156 - learning_rate: 1.0000e-04\n",
      "Epoch 58/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6788 - val_loss: 1.2795 - learning_rate: 1.0000e-04\n",
      "Epoch 59/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6942 - val_loss: 1.2460 - learning_rate: 1.0000e-04\n",
      "Epoch 60/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6676 - val_loss: 1.2040 - learning_rate: 1.0000e-04\n",
      "Epoch 61/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6001 - val_loss: 1.1707 - learning_rate: 1.0000e-04\n",
      "Epoch 62/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8902 - val_loss: 1.1286 - learning_rate: 1.0000e-04\n",
      "Epoch 63/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6086 - val_loss: 1.0990 - learning_rate: 1.0000e-04\n",
      "Epoch 64/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6047 - val_loss: 1.0734 - learning_rate: 1.0000e-04\n",
      "Epoch 65/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4308 - val_loss: 1.0464 - learning_rate: 1.0000e-04\n",
      "Epoch 66/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5634 - val_loss: 1.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 67/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5210 - val_loss: 0.9810 - learning_rate: 1.0000e-04\n",
      "Epoch 68/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7765 - val_loss: 0.9483 - learning_rate: 1.0000e-04\n",
      "Epoch 69/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6944 - val_loss: 0.9303 - learning_rate: 1.0000e-04\n",
      "Epoch 70/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5502 - val_loss: 0.8967 - learning_rate: 1.0000e-04\n",
      "Epoch 71/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4130 - val_loss: 0.8733 - learning_rate: 1.0000e-04\n",
      "Epoch 72/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3437 - val_loss: 0.8490 - learning_rate: 1.0000e-04\n",
      "Epoch 73/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4895 - val_loss: 0.8263 - learning_rate: 1.0000e-04\n",
      "Epoch 74/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2566 - val_loss: 0.8247 - learning_rate: 1.0000e-04\n",
      "Epoch 75/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5033 - val_loss: 0.7801 - learning_rate: 1.0000e-04\n",
      "Epoch 76/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2672 - val_loss: 0.7597 - learning_rate: 1.0000e-04\n",
      "Epoch 77/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1930 - val_loss: 0.7405 - learning_rate: 1.0000e-04\n",
      "Epoch 78/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2653 - val_loss: 0.7264 - learning_rate: 1.0000e-04\n",
      "Epoch 79/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3512 - val_loss: 0.7117 - learning_rate: 1.0000e-04\n",
      "Epoch 80/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3550 - val_loss: 0.6879 - learning_rate: 1.0000e-04\n",
      "Epoch 81/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2849 - val_loss: 0.6811 - learning_rate: 1.0000e-04\n",
      "Epoch 82/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2447 - val_loss: 0.6612 - learning_rate: 1.0000e-04\n",
      "Epoch 83/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2103 - val_loss: 0.6362 - learning_rate: 1.0000e-04\n",
      "Epoch 84/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1742 - val_loss: 0.6232 - learning_rate: 1.0000e-04\n",
      "Epoch 85/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2029 - val_loss: 0.6214 - learning_rate: 1.0000e-04\n",
      "Epoch 86/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2190 - val_loss: 0.5922 - learning_rate: 1.0000e-04\n",
      "Epoch 87/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2428 - val_loss: 0.5871 - learning_rate: 1.0000e-04\n",
      "Epoch 88/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2166 - val_loss: 0.5653 - learning_rate: 1.0000e-04\n",
      "Epoch 89/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1372 - val_loss: 0.5625 - learning_rate: 1.0000e-04\n",
      "Epoch 90/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1546 - val_loss: 0.5478 - learning_rate: 1.0000e-04\n",
      "Epoch 91/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1678 - val_loss: 0.5403 - learning_rate: 1.0000e-04\n",
      "Epoch 92/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1366 - val_loss: 0.5275 - learning_rate: 1.0000e-04\n",
      "Epoch 93/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1434 - val_loss: 0.5079 - learning_rate: 1.0000e-04\n",
      "Epoch 94/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1697 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
      "Epoch 95/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1132 - val_loss: 0.5091 - learning_rate: 1.0000e-04\n",
      "Epoch 96/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0129 - val_loss: 0.4790 - learning_rate: 1.0000e-04\n",
      "Epoch 97/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0616 - val_loss: 0.4676 - learning_rate: 1.0000e-04\n",
      "Epoch 98/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0294 - val_loss: 0.4747 - learning_rate: 1.0000e-04\n",
      "Epoch 99/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9384 - val_loss: 0.4460 - learning_rate: 1.0000e-04\n",
      "Epoch 100/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0297 - val_loss: 0.4391 - learning_rate: 1.0000e-04\n",
      "Epoch 101/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1283 - val_loss: 0.4316 - learning_rate: 1.0000e-04\n",
      "Epoch 102/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0214 - val_loss: 0.4262 - learning_rate: 1.0000e-04\n",
      "Epoch 103/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0280 - val_loss: 0.4202 - learning_rate: 1.0000e-04\n",
      "Epoch 104/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0303 - val_loss: 0.4142 - learning_rate: 1.0000e-04\n",
      "Epoch 105/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0794 - val_loss: 0.4173 - learning_rate: 1.0000e-04\n",
      "Epoch 106/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0967 - val_loss: 0.3945 - learning_rate: 1.0000e-04\n",
      "Epoch 107/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9735 - val_loss: 0.3880 - learning_rate: 1.0000e-04\n",
      "Epoch 108/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0330 - val_loss: 0.3941 - learning_rate: 1.0000e-04\n",
      "Epoch 109/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9933 - val_loss: 0.3814 - learning_rate: 1.0000e-04\n",
      "Epoch 110/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9514 - val_loss: 0.3678 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9902 - val_loss: 0.3695 - learning_rate: 1.0000e-04\n",
      "Epoch 112/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9386 - val_loss: 0.3584 - learning_rate: 1.0000e-04\n",
      "Epoch 113/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9473 - val_loss: 0.3696 - learning_rate: 1.0000e-04\n",
      "Epoch 114/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9400 - val_loss: 0.3800 - learning_rate: 1.0000e-04\n",
      "Epoch 115/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8919 - val_loss: 0.3405 - learning_rate: 1.0000e-04\n",
      "Epoch 116/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9989 - val_loss: 0.3297 - learning_rate: 1.0000e-04\n",
      "Epoch 117/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9511 - val_loss: 0.3286 - learning_rate: 1.0000e-04\n",
      "Epoch 118/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9869 - val_loss: 0.3327 - learning_rate: 1.0000e-04\n",
      "Epoch 119/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8832 - val_loss: 0.3165 - learning_rate: 1.0000e-04\n",
      "Epoch 120/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8729 - val_loss: 0.3111 - learning_rate: 1.0000e-04\n",
      "Epoch 121/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9875 - val_loss: 0.3077 - learning_rate: 1.0000e-04\n",
      "Epoch 122/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8811 - val_loss: 0.3063 - learning_rate: 1.0000e-04\n",
      "Epoch 123/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9150 - val_loss: 0.3079 - learning_rate: 1.0000e-04\n",
      "Epoch 124/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9205 - val_loss: 0.2951 - learning_rate: 1.0000e-04\n",
      "Epoch 125/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8673 - val_loss: 0.3362 - learning_rate: 1.0000e-04\n",
      "Epoch 126/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8932 - val_loss: 0.2912 - learning_rate: 1.0000e-04\n",
      "Epoch 127/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8559 - val_loss: 0.2891 - learning_rate: 1.0000e-04\n",
      "Epoch 128/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8716 - val_loss: 0.2889 - learning_rate: 1.0000e-04\n",
      "Epoch 129/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9057 - val_loss: 0.2756 - learning_rate: 1.0000e-04\n",
      "Epoch 130/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9170 - val_loss: 0.2873 - learning_rate: 1.0000e-04\n",
      "Epoch 131/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7903 - val_loss: 0.2764 - learning_rate: 1.0000e-04\n",
      "Epoch 132/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8979 - val_loss: 0.2714 - learning_rate: 1.0000e-04\n",
      "Epoch 133/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8883 - val_loss: 0.2649 - learning_rate: 1.0000e-04\n",
      "Epoch 134/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8568 - val_loss: 0.2618 - learning_rate: 1.0000e-04\n",
      "Epoch 135/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8321 - val_loss: 0.2713 - learning_rate: 1.0000e-04\n",
      "Epoch 136/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8965 - val_loss: 0.2581 - learning_rate: 1.0000e-04\n",
      "Epoch 137/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8363 - val_loss: 0.2545 - learning_rate: 1.0000e-04\n",
      "Epoch 138/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8333 - val_loss: 0.2508 - learning_rate: 1.0000e-04\n",
      "Epoch 139/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8826 - val_loss: 0.2464 - learning_rate: 1.0000e-04\n",
      "Epoch 140/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9734 - val_loss: 0.2415 - learning_rate: 1.0000e-04\n",
      "Epoch 141/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8299 - val_loss: 0.2583 - learning_rate: 1.0000e-04\n",
      "Epoch 142/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8225 - val_loss: 0.2368 - learning_rate: 1.0000e-04\n",
      "Epoch 143/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8344 - val_loss: 0.2441 - learning_rate: 1.0000e-04\n",
      "Epoch 144/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8891 - val_loss: 0.2480 - learning_rate: 1.0000e-04\n",
      "Epoch 145/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8261 - val_loss: 0.2405 - learning_rate: 1.0000e-04\n",
      "Epoch 146/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8769 - val_loss: 0.2311 - learning_rate: 1.0000e-04\n",
      "Epoch 147/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8718 - val_loss: 0.2308 - learning_rate: 1.0000e-04\n",
      "Epoch 148/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8102 - val_loss: 0.2229 - learning_rate: 1.0000e-04\n",
      "Epoch 149/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7914 - val_loss: 0.2252 - learning_rate: 1.0000e-04\n",
      "Epoch 150/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9075 - val_loss: 0.2191 - learning_rate: 1.0000e-04\n",
      "Epoch 151/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8314 - val_loss: 0.2310 - learning_rate: 1.0000e-04\n",
      "Epoch 152/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8407 - val_loss: 0.2517 - learning_rate: 1.0000e-04\n",
      "Epoch 153/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8285 - val_loss: 0.2123 - learning_rate: 1.0000e-04\n",
      "Epoch 154/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7992 - val_loss: 0.2435 - learning_rate: 1.0000e-04\n",
      "Epoch 155/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8685 - val_loss: 0.2111 - learning_rate: 1.0000e-04\n",
      "Epoch 156/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7991 - val_loss: 0.2067 - learning_rate: 1.0000e-04\n",
      "Epoch 157/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7786 - val_loss: 0.2079 - learning_rate: 1.0000e-04\n",
      "Epoch 158/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8109 - val_loss: 0.2091 - learning_rate: 1.0000e-04\n",
      "Epoch 159/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8957 - val_loss: 0.2061 - learning_rate: 1.0000e-04\n",
      "Epoch 160/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7990 - val_loss: 0.2028 - learning_rate: 1.0000e-04\n",
      "Epoch 161/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8213 - val_loss: 0.2041 - learning_rate: 1.0000e-04\n",
      "Epoch 162/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8107 - val_loss: 0.2130 - learning_rate: 1.0000e-04\n",
      "Epoch 163/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8268 - val_loss: 0.1986 - learning_rate: 1.0000e-04\n",
      "Epoch 164/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7848 - val_loss: 0.1968 - learning_rate: 1.0000e-04\n",
      "Epoch 165/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7617 - val_loss: 0.1939 - learning_rate: 1.0000e-04\n",
      "Epoch 166/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8338 - val_loss: 0.1997 - learning_rate: 1.0000e-04\n",
      "Epoch 167/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8078 - val_loss: 0.1891 - learning_rate: 1.0000e-04\n",
      "Epoch 168/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8006 - val_loss: 0.2103 - learning_rate: 1.0000e-04\n",
      "Epoch 169/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8484 - val_loss: 0.1865 - learning_rate: 1.0000e-04\n",
      "Epoch 170/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8369 - val_loss: 0.2015 - learning_rate: 1.0000e-04\n",
      "Epoch 171/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8165 - val_loss: 0.1824 - learning_rate: 1.0000e-04\n",
      "Epoch 172/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8104 - val_loss: 0.1849 - learning_rate: 1.0000e-04\n",
      "Epoch 173/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8184 - val_loss: 0.1835 - learning_rate: 1.0000e-04\n",
      "Epoch 174/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7799 - val_loss: 0.1828 - learning_rate: 1.0000e-04\n",
      "Epoch 175/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8392 - val_loss: 0.1784 - learning_rate: 1.0000e-04\n",
      "Epoch 176/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7897 - val_loss: 0.1780 - learning_rate: 1.0000e-04\n",
      "Epoch 177/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8584 - val_loss: 0.2013 - learning_rate: 1.0000e-04\n",
      "Epoch 178/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7229 - val_loss: 0.1993 - learning_rate: 1.0000e-04\n",
      "Epoch 179/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7975 - val_loss: 0.1763 - learning_rate: 1.0000e-04\n",
      "Epoch 180/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8987 - val_loss: 0.1724 - learning_rate: 1.0000e-04\n",
      "Epoch 181/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8150 - val_loss: 0.1807 - learning_rate: 1.0000e-04\n",
      "Epoch 182/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7923 - val_loss: 0.1672 - learning_rate: 1.0000e-04\n",
      "Epoch 183/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7594 - val_loss: 0.1927 - learning_rate: 1.0000e-04\n",
      "Epoch 184/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7910 - val_loss: 0.1748 - learning_rate: 1.0000e-04\n",
      "Epoch 185/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8584 - val_loss: 0.1674 - learning_rate: 1.0000e-04\n",
      "Epoch 186/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8572 - val_loss: 0.1708 - learning_rate: 1.0000e-04\n",
      "Epoch 187/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7555 - val_loss: 0.1635 - learning_rate: 1.0000e-04\n",
      "Epoch 188/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7901 - val_loss: 0.1655 - learning_rate: 1.0000e-04\n",
      "Epoch 189/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8665 - val_loss: 0.1772 - learning_rate: 1.0000e-04\n",
      "Epoch 190/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7655 - val_loss: 0.1626 - learning_rate: 1.0000e-04\n",
      "Epoch 191/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8189 - val_loss: 0.1604 - learning_rate: 1.0000e-04\n",
      "Epoch 192/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8257 - val_loss: 0.1567 - learning_rate: 1.0000e-04\n",
      "Epoch 193/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7573 - val_loss: 0.1714 - learning_rate: 1.0000e-04\n",
      "Epoch 194/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7514 - val_loss: 0.1552 - learning_rate: 1.0000e-04\n",
      "Epoch 195/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7757 - val_loss: 0.1826 - learning_rate: 1.0000e-04\n",
      "Epoch 196/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8060 - val_loss: 0.2259 - learning_rate: 1.0000e-04\n",
      "Epoch 197/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7511 - val_loss: 0.1524 - learning_rate: 1.0000e-04\n",
      "Epoch 198/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7973 - val_loss: 0.1716 - learning_rate: 1.0000e-04\n",
      "Epoch 199/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7994 - val_loss: 0.1869 - learning_rate: 1.0000e-04\n",
      "Epoch 200/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7540 - val_loss: 0.1576 - learning_rate: 1.0000e-04\n",
      "Epoch 201/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8363 - val_loss: 0.1498 - learning_rate: 1.0000e-04\n",
      "Epoch 202/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8569 - val_loss: 0.1481 - learning_rate: 1.0000e-04\n",
      "Epoch 203/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7863 - val_loss: 0.1934 - learning_rate: 1.0000e-04\n",
      "Epoch 204/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7965 - val_loss: 0.1454 - learning_rate: 1.0000e-04\n",
      "Epoch 205/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7489 - val_loss: 0.1451 - learning_rate: 1.0000e-04\n",
      "Epoch 206/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8499 - val_loss: 0.1527 - learning_rate: 1.0000e-04\n",
      "Epoch 207/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8763 - val_loss: 0.1581 - learning_rate: 1.0000e-04\n",
      "Epoch 208/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7352 - val_loss: 0.1458 - learning_rate: 1.0000e-04\n",
      "Epoch 209/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7598 - val_loss: 0.1697 - learning_rate: 1.0000e-04\n",
      "Epoch 210/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7482 - val_loss: 0.1452 - learning_rate: 1.0000e-04\n",
      "Epoch 211/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7685 - val_loss: 0.1680 - learning_rate: 1.0000e-04\n",
      "Epoch 212/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8745 - val_loss: 0.1418 - learning_rate: 1.0000e-04\n",
      "Epoch 213/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7577 - val_loss: 0.1759 - learning_rate: 1.0000e-04\n",
      "Epoch 214/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8032 - val_loss: 0.1497 - learning_rate: 1.0000e-04\n",
      "Epoch 215/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7867 - val_loss: 0.1356 - learning_rate: 1.0000e-04\n",
      "Epoch 216/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7295 - val_loss: 0.1587 - learning_rate: 1.0000e-04\n",
      "Epoch 217/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7235 - val_loss: 0.1358 - learning_rate: 1.0000e-04\n",
      "Epoch 218/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8060 - val_loss: 0.1359 - learning_rate: 1.0000e-04\n",
      "Epoch 219/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6870 - val_loss: 0.1465 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7279 - val_loss: 0.1832 - learning_rate: 1.0000e-04\n",
      "Epoch 221/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7740 - val_loss: 0.1334 - learning_rate: 1.0000e-04\n",
      "Epoch 222/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7459 - val_loss: 0.1351 - learning_rate: 1.0000e-04\n",
      "Epoch 223/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7371 - val_loss: 0.1599 - learning_rate: 1.0000e-04\n",
      "Epoch 224/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7602 - val_loss: 0.1369 - learning_rate: 1.0000e-04\n",
      "Epoch 225/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7655 - val_loss: 0.1294 - learning_rate: 1.0000e-04\n",
      "Epoch 226/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7549 - val_loss: 0.1281 - learning_rate: 1.0000e-04\n",
      "Epoch 227/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8070 - val_loss: 0.1298 - learning_rate: 1.0000e-04\n",
      "Epoch 228/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6951 - val_loss: 0.1285 - learning_rate: 1.0000e-04\n",
      "Epoch 229/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7176 - val_loss: 0.1448 - learning_rate: 1.0000e-04\n",
      "Epoch 230/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6428 - val_loss: 0.1302 - learning_rate: 1.0000e-04\n",
      "Epoch 231/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7408 - val_loss: 0.1256 - learning_rate: 1.0000e-04\n",
      "Epoch 232/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7465 - val_loss: 0.1245 - learning_rate: 1.0000e-04\n",
      "Epoch 233/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7473 - val_loss: 0.1251 - learning_rate: 1.0000e-04\n",
      "Epoch 234/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7209 - val_loss: 0.1339 - learning_rate: 1.0000e-04\n",
      "Epoch 235/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7259 - val_loss: 0.1757 - learning_rate: 1.0000e-04\n",
      "Epoch 236/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6986 - val_loss: 0.1414 - learning_rate: 1.0000e-04\n",
      "Epoch 237/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6995 - val_loss: 0.1337 - learning_rate: 1.0000e-04\n",
      "Epoch 238/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6843 - val_loss: 0.1280 - learning_rate: 1.0000e-04\n",
      "Epoch 239/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7095 - val_loss: 0.1250 - learning_rate: 1.0000e-04\n",
      "Epoch 240/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6908 - val_loss: 0.1567 - learning_rate: 1.0000e-04\n",
      "Epoch 241/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8527 - val_loss: 0.1204 - learning_rate: 1.0000e-04\n",
      "Epoch 242/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6813 - val_loss: 0.1339 - learning_rate: 1.0000e-04\n",
      "Epoch 243/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7738 - val_loss: 0.1184 - learning_rate: 1.0000e-04\n",
      "Epoch 244/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6598 - val_loss: 0.1628 - learning_rate: 1.0000e-04\n",
      "Epoch 245/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7479 - val_loss: 0.1378 - learning_rate: 1.0000e-04\n",
      "Epoch 246/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6978 - val_loss: 0.1299 - learning_rate: 1.0000e-04\n",
      "Epoch 247/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7153 - val_loss: 0.1176 - learning_rate: 1.0000e-04\n",
      "Epoch 248/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7153 - val_loss: 0.1224 - learning_rate: 1.0000e-04\n",
      "Epoch 249/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6867 - val_loss: 0.1341 - learning_rate: 1.0000e-04\n",
      "Epoch 250/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6795 - val_loss: 0.1149 - learning_rate: 1.0000e-04\n",
      "Epoch 251/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7494 - val_loss: 0.1509 - learning_rate: 1.0000e-04\n",
      "Epoch 252/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6918 - val_loss: 0.1131 - learning_rate: 1.0000e-04\n",
      "Epoch 253/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7216 - val_loss: 0.1518 - learning_rate: 1.0000e-04\n",
      "Epoch 254/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6882 - val_loss: 0.1201 - learning_rate: 1.0000e-04\n",
      "Epoch 255/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7025 - val_loss: 0.1166 - learning_rate: 1.0000e-04\n",
      "Epoch 256/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7262 - val_loss: 0.1282 - learning_rate: 1.0000e-04\n",
      "Epoch 257/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7391 - val_loss: 0.1171 - learning_rate: 1.0000e-04\n",
      "Epoch 258/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6502 - val_loss: 0.1100 - learning_rate: 1.0000e-04\n",
      "Epoch 259/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8396 - val_loss: 0.1177 - learning_rate: 1.0000e-04\n",
      "Epoch 260/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7420 - val_loss: 0.1099 - learning_rate: 1.0000e-04\n",
      "Epoch 261/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7163 - val_loss: 0.1182 - learning_rate: 1.0000e-04\n",
      "Epoch 262/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7297 - val_loss: 0.1099 - learning_rate: 1.0000e-04\n",
      "Epoch 263/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6905 - val_loss: 0.1213 - learning_rate: 1.0000e-04\n",
      "Epoch 264/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6639 - val_loss: 0.1110 - learning_rate: 1.0000e-04\n",
      "Epoch 265/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7543 - val_loss: 0.1275 - learning_rate: 1.0000e-04\n",
      "Epoch 266/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6990 - val_loss: 0.1115 - learning_rate: 1.0000e-04\n",
      "Epoch 267/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6679 - val_loss: 0.1169 - learning_rate: 1.0000e-04\n",
      "Epoch 268/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7535 - val_loss: 0.1094 - learning_rate: 1.0000e-04\n",
      "Epoch 269/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7462 - val_loss: 0.1115 - learning_rate: 1.0000e-04\n",
      "Epoch 270/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7356 - val_loss: 0.1132 - learning_rate: 1.0000e-04\n",
      "Epoch 271/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7211 - val_loss: 0.1097 - learning_rate: 1.0000e-04\n",
      "Epoch 272/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6456 - val_loss: 0.1057 - learning_rate: 1.0000e-04\n",
      "Epoch 273/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6621 - val_loss: 0.1057 - learning_rate: 1.0000e-04\n",
      "Epoch 274/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6775 - val_loss: 0.1058 - learning_rate: 1.0000e-04\n",
      "Epoch 275/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7358 - val_loss: 0.1075 - learning_rate: 1.0000e-04\n",
      "Epoch 276/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7446 - val_loss: 0.1196 - learning_rate: 1.0000e-04\n",
      "Epoch 277/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7185 - val_loss: 0.1045 - learning_rate: 1.0000e-04\n",
      "Epoch 278/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6682 - val_loss: 0.1046 - learning_rate: 1.0000e-04\n",
      "Epoch 279/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7817 - val_loss: 0.1088 - learning_rate: 1.0000e-04\n",
      "Epoch 280/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7408 - val_loss: 0.1308 - learning_rate: 1.0000e-04\n",
      "Epoch 281/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7130 - val_loss: 0.1046 - learning_rate: 1.0000e-04\n",
      "Epoch 282/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6597 - val_loss: 0.1029 - learning_rate: 1.0000e-04\n",
      "Epoch 283/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6928 - val_loss: 0.1294 - learning_rate: 1.0000e-04\n",
      "Epoch 284/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7046 - val_loss: 0.1046 - learning_rate: 1.0000e-04\n",
      "Epoch 285/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7020 - val_loss: 0.1032 - learning_rate: 1.0000e-04\n",
      "Epoch 286/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7240 - val_loss: 0.1025 - learning_rate: 1.0000e-04\n",
      "Epoch 287/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6980 - val_loss: 0.1002 - learning_rate: 1.0000e-04\n",
      "Epoch 288/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6675 - val_loss: 0.1297 - learning_rate: 1.0000e-04\n",
      "Epoch 289/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7054 - val_loss: 0.1171 - learning_rate: 1.0000e-04\n",
      "Epoch 290/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6780 - val_loss: 0.1184 - learning_rate: 1.0000e-04\n",
      "Epoch 291/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6946 - val_loss: 0.1320 - learning_rate: 1.0000e-04\n",
      "Epoch 292/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6836 - val_loss: 0.1030 - learning_rate: 1.0000e-04\n",
      "Epoch 293/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6981 - val_loss: 0.1048 - learning_rate: 1.0000e-04\n",
      "Epoch 294/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7377 - val_loss: 0.0983 - learning_rate: 1.0000e-04\n",
      "Epoch 295/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6537 - val_loss: 0.1015 - learning_rate: 1.0000e-04\n",
      "Epoch 296/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6667 - val_loss: 0.1409 - learning_rate: 1.0000e-04\n",
      "Epoch 297/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6493 - val_loss: 0.0979 - learning_rate: 1.0000e-04\n",
      "Epoch 298/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7011 - val_loss: 0.0992 - learning_rate: 1.0000e-04\n",
      "Epoch 299/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6917 - val_loss: 0.0970 - learning_rate: 1.0000e-04\n",
      "Epoch 300/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6512 - val_loss: 0.1392 - learning_rate: 1.0000e-04\n",
      "Epoch 301/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.1216 - learning_rate: 1.0000e-04\n",
      "Epoch 302/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6722 - val_loss: 0.0937 - learning_rate: 1.0000e-04\n",
      "Epoch 303/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6437 - val_loss: 0.1061 - learning_rate: 1.0000e-04\n",
      "Epoch 304/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6359 - val_loss: 0.1064 - learning_rate: 1.0000e-04\n",
      "Epoch 305/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6503 - val_loss: 0.1186 - learning_rate: 1.0000e-04\n",
      "Epoch 306/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7475 - val_loss: 0.1309 - learning_rate: 1.0000e-04\n",
      "Epoch 307/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6473 - val_loss: 0.0918 - learning_rate: 1.0000e-04\n",
      "Epoch 308/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6524 - val_loss: 0.0969 - learning_rate: 1.0000e-04\n",
      "Epoch 309/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6267 - val_loss: 0.0929 - learning_rate: 1.0000e-04\n",
      "Epoch 310/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6585 - val_loss: 0.0956 - learning_rate: 1.0000e-04\n",
      "Epoch 311/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6902 - val_loss: 0.0921 - learning_rate: 1.0000e-04\n",
      "Epoch 312/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6637 - val_loss: 0.0929 - learning_rate: 1.0000e-04\n",
      "Epoch 313/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7121 - val_loss: 0.0932 - learning_rate: 1.0000e-04\n",
      "Epoch 314/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6280 - val_loss: 0.0959 - learning_rate: 1.0000e-04\n",
      "Epoch 315/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7182 - val_loss: 0.0914 - learning_rate: 1.0000e-04\n",
      "Epoch 316/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6833 - val_loss: 0.0955 - learning_rate: 1.0000e-04\n",
      "Epoch 317/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6496 - val_loss: 0.1001 - learning_rate: 1.0000e-04\n",
      "Epoch 318/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6179 - val_loss: 0.0901 - learning_rate: 1.0000e-04\n",
      "Epoch 319/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6317 - val_loss: 0.0955 - learning_rate: 1.0000e-04\n",
      "Epoch 320/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6499 - val_loss: 0.0891 - learning_rate: 1.0000e-04\n",
      "Epoch 321/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6753 - val_loss: 0.0981 - learning_rate: 1.0000e-04\n",
      "Epoch 322/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6344 - val_loss: 0.1292 - learning_rate: 1.0000e-04\n",
      "Epoch 323/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6571 - val_loss: 0.0881 - learning_rate: 1.0000e-04\n",
      "Epoch 324/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6288 - val_loss: 0.0885 - learning_rate: 1.0000e-04\n",
      "Epoch 325/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6689 - val_loss: 0.1356 - learning_rate: 1.0000e-04\n",
      "Epoch 326/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6547 - val_loss: 0.1044 - learning_rate: 1.0000e-04\n",
      "Epoch 327/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7603 - val_loss: 0.1017 - learning_rate: 1.0000e-04\n",
      "Epoch 328/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6407 - val_loss: 0.0909 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7172 - val_loss: 0.0903 - learning_rate: 1.0000e-04\n",
      "Epoch 330/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6873 - val_loss: 0.1029 - learning_rate: 1.0000e-04\n",
      "Epoch 331/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6691 - val_loss: 0.0946 - learning_rate: 1.0000e-04\n",
      "Epoch 332/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6572 - val_loss: 0.0879 - learning_rate: 1.0000e-04\n",
      "Epoch 333/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6125 - val_loss: 0.1025 - learning_rate: 1.0000e-04\n",
      "Epoch 334/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6787 - val_loss: 0.0896 - learning_rate: 1.0000e-04\n",
      "Epoch 335/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7250 - val_loss: 0.0909 - learning_rate: 1.0000e-04\n",
      "Epoch 336/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6973 - val_loss: 0.0865 - learning_rate: 1.0000e-04\n",
      "Epoch 337/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6570 - val_loss: 0.0834 - learning_rate: 1.0000e-04\n",
      "Epoch 338/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6744 - val_loss: 0.1088 - learning_rate: 1.0000e-04\n",
      "Epoch 339/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6546 - val_loss: 0.1016 - learning_rate: 1.0000e-04\n",
      "Epoch 340/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6194 - val_loss: 0.0918 - learning_rate: 1.0000e-04\n",
      "Epoch 341/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6591 - val_loss: 0.1081 - learning_rate: 1.0000e-04\n",
      "Epoch 342/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6373 - val_loss: 0.0928 - learning_rate: 1.0000e-04\n",
      "Epoch 343/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6658 - val_loss: 0.0840 - learning_rate: 1.0000e-04\n",
      "Epoch 344/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6596 - val_loss: 0.0987 - learning_rate: 1.0000e-04\n",
      "Epoch 345/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6369 - val_loss: 0.1296 - learning_rate: 1.0000e-04\n",
      "Epoch 346/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6606 - val_loss: 0.1027 - learning_rate: 1.0000e-04\n",
      "Epoch 347/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6606 - val_loss: 0.0828 - learning_rate: 1.0000e-04\n",
      "Epoch 348/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6228 - val_loss: 0.0817 - learning_rate: 1.0000e-04\n",
      "Epoch 349/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6583 - val_loss: 0.0864 - learning_rate: 1.0000e-04\n",
      "Epoch 350/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6620 - val_loss: 0.0821 - learning_rate: 1.0000e-04\n",
      "Epoch 351/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6364 - val_loss: 0.0980 - learning_rate: 1.0000e-04\n",
      "Epoch 352/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6770 - val_loss: 0.0898 - learning_rate: 1.0000e-04\n",
      "Epoch 353/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6364 - val_loss: 0.0839 - learning_rate: 1.0000e-04\n",
      "Epoch 354/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6262 - val_loss: 0.1000 - learning_rate: 1.0000e-04\n",
      "Epoch 355/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6597 - val_loss: 0.0969 - learning_rate: 1.0000e-04\n",
      "Epoch 356/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6628 - val_loss: 0.1094 - learning_rate: 1.0000e-04\n",
      "Epoch 357/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6919 - val_loss: 0.0790 - learning_rate: 1.0000e-04\n",
      "Epoch 358/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6327 - val_loss: 0.0781 - learning_rate: 1.0000e-04\n",
      "Epoch 359/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6979 - val_loss: 0.0974 - learning_rate: 1.0000e-04\n",
      "Epoch 360/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6506 - val_loss: 0.0956 - learning_rate: 1.0000e-04\n",
      "Epoch 361/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6657 - val_loss: 0.0868 - learning_rate: 1.0000e-04\n",
      "Epoch 362/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6109 - val_loss: 0.0802 - learning_rate: 1.0000e-04\n",
      "Epoch 363/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6892 - val_loss: 0.0868 - learning_rate: 1.0000e-04\n",
      "Epoch 364/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6521 - val_loss: 0.0769 - learning_rate: 1.0000e-04\n",
      "Epoch 365/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6435 - val_loss: 0.0978 - learning_rate: 1.0000e-04\n",
      "Epoch 366/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6797 - val_loss: 0.0957 - learning_rate: 1.0000e-04\n",
      "Epoch 367/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6423 - val_loss: 0.0760 - learning_rate: 1.0000e-04\n",
      "Epoch 368/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6011 - val_loss: 0.0840 - learning_rate: 1.0000e-04\n",
      "Epoch 369/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6389 - val_loss: 0.0797 - learning_rate: 1.0000e-04\n",
      "Epoch 370/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6125 - val_loss: 0.0840 - learning_rate: 1.0000e-04\n",
      "Epoch 371/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6119 - val_loss: 0.1286 - learning_rate: 1.0000e-04\n",
      "Epoch 372/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6425 - val_loss: 0.0890 - learning_rate: 1.0000e-04\n",
      "Epoch 373/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6238 - val_loss: 0.1384 - learning_rate: 1.0000e-04\n",
      "Epoch 374/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6615 - val_loss: 0.0851 - learning_rate: 1.0000e-04\n",
      "Epoch 375/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6870 - val_loss: 0.0790 - learning_rate: 1.0000e-04\n",
      "Epoch 376/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6463 - val_loss: 0.0754 - learning_rate: 1.0000e-04\n",
      "Epoch 377/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6074 - val_loss: 0.0739 - learning_rate: 1.0000e-04\n",
      "Epoch 378/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6283 - val_loss: 0.0900 - learning_rate: 1.0000e-04\n",
      "Epoch 379/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6268 - val_loss: 0.0964 - learning_rate: 1.0000e-04\n",
      "Epoch 380/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6033 - val_loss: 0.0760 - learning_rate: 1.0000e-04\n",
      "Epoch 381/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6599 - val_loss: 0.0739 - learning_rate: 1.0000e-04\n",
      "Epoch 382/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6597 - val_loss: 0.0807 - learning_rate: 1.0000e-04\n",
      "Epoch 383/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6720 - val_loss: 0.0755 - learning_rate: 1.0000e-04\n",
      "Epoch 384/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6337 - val_loss: 0.0728 - learning_rate: 1.0000e-04\n",
      "Epoch 385/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5754 - val_loss: 0.0771 - learning_rate: 1.0000e-04\n",
      "Epoch 386/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7109 - val_loss: 0.0751 - learning_rate: 1.0000e-04\n",
      "Epoch 387/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6179 - val_loss: 0.0791 - learning_rate: 1.0000e-04\n",
      "Epoch 388/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6531 - val_loss: 0.0716 - learning_rate: 1.0000e-04\n",
      "Epoch 389/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6128 - val_loss: 0.0782 - learning_rate: 1.0000e-04\n",
      "Epoch 390/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6502 - val_loss: 0.0788 - learning_rate: 1.0000e-04\n",
      "Epoch 391/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6846 - val_loss: 0.0823 - learning_rate: 1.0000e-04\n",
      "Epoch 392/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6212 - val_loss: 0.0732 - learning_rate: 1.0000e-04\n",
      "Epoch 393/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6450 - val_loss: 0.0728 - learning_rate: 1.0000e-04\n",
      "Epoch 394/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6179 - val_loss: 0.0791 - learning_rate: 1.0000e-04\n",
      "Epoch 395/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6336 - val_loss: 0.0718 - learning_rate: 1.0000e-04\n",
      "Epoch 396/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6201 - val_loss: 0.0713 - learning_rate: 1.0000e-04\n",
      "Epoch 397/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6322 - val_loss: 0.0890 - learning_rate: 1.0000e-04\n",
      "Epoch 398/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5900 - val_loss: 0.0854 - learning_rate: 1.0000e-04\n",
      "Epoch 399/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6464 - val_loss: 0.1338 - learning_rate: 1.0000e-04\n",
      "Epoch 400/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6574 - val_loss: 0.0690 - learning_rate: 1.0000e-04\n",
      "Epoch 401/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5438 - val_loss: 0.0753 - learning_rate: 1.0000e-04\n",
      "Epoch 402/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6178 - val_loss: 0.0692 - learning_rate: 1.0000e-04\n",
      "Epoch 403/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6398 - val_loss: 0.0877 - learning_rate: 1.0000e-04\n",
      "Epoch 404/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6397 - val_loss: 0.0848 - learning_rate: 1.0000e-04\n",
      "Epoch 405/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5950 - val_loss: 0.0697 - learning_rate: 1.0000e-04\n",
      "Epoch 406/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6834 - val_loss: 0.0938 - learning_rate: 1.0000e-04\n",
      "Epoch 407/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6561 - val_loss: 0.0841 - learning_rate: 1.0000e-04\n",
      "Epoch 408/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6321 - val_loss: 0.0715 - learning_rate: 1.0000e-04\n",
      "Epoch 409/2000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5825 - val_loss: 0.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 410/2000\n",
      "\u001b[1m73/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6375\n",
      "Epoch 410: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6351 - val_loss: 0.1279 - learning_rate: 1.0000e-04\n",
      "Epoch 410: early stopping\n",
      "Restoring model weights from the end of the best epoch: 400.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size=32,  validation_split=0.2, verbose=1, callbacks=[early_stopping, reduce_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09e3e4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXT0lEQVR4nO3deXwTdf4/8NfkbJKm6QFtWiilCMiNSKECKiA3yor1YAEVFi/kUHRdFFGproLHguii+NNVwANxPWD9LooUFXStaD2qXCJihSKthV7pmWs+vz/ShIaWo0noNO3r+XjMg3ZmMnl/MtW++vl8ZkYSQggQERERhSmV0gUQERERBYNhhoiIiMIawwwRERGFNYYZIiIiCmsMM0RERBTWGGaIiIgorDHMEBERUVhjmCEiIqKwxjBDREREYY1hhoh81q5dC0mSIEkStm/f3mC7EAJdu3aFJEkYMWJESN9bkiRkZmY2+XW//fYbJEnC2rVrz2q/f/zjH4EVSEQtFsMMETVgNpvx8ssvN1i/Y8cOHDx4EGazWYGqiIgaxzBDRA1MmTIF7777Lmw2m9/6l19+GUOGDEGnTp0UqoyIqCGGGSJqYOrUqQCAN99807euvLwc7777LmbNmtXoa0pKSjBnzhx06NABOp0OXbp0weLFi2G32/32s9lsuOWWWxAXF4fIyEiMHz8eP//8c6PHPHDgAKZNm4b4+Hjo9Xr07NkTzz33XIha2bjDhw/j+uuv93vP5cuXQ5Zlv/1Wr16N/v37IzIyEmazGT169MD999/v215dXY177rkHqampiIiIQGxsLNLS0vw+UyIKDY3SBRBRyxMVFYVrrrkGr7zyCm677TYAnmCjUqkwZcoUrFy50m//2tpajBw5EgcPHsTDDz+Mfv364fPPP8eyZcuQm5uLzZs3A/DMuZk8eTKys7Px0EMPYdCgQfjiiy8wYcKEBjXs3bsXQ4cORadOnbB8+XJYrVZ89NFHuOOOO3D8+HEsWbIk5O0+duwYhg4dCofDgb///e/o3Lkz/vvf/+Kee+7BwYMH8fzzzwMANmzYgDlz5mD+/Pn4xz/+AZVKhV9++QV79+71Hevuu+/Ga6+9hkcffRQDBgxAVVUVdu/ejeLi4pDXTdTmCSKiOmvWrBEARE5Ojvj0008FALF7924hhBCDBg0SM2fOFEII0bt3bzF8+HDf61544QUBQPz73//2O94TTzwhAIitW7cKIYT48MMPBQDxzDPP+O332GOPCQBiyZIlvnXjxo0THTt2FOXl5X77zps3T0RERIiSkhIhhBB5eXkCgFizZs1p2+bd76mnnjrlPvfdd58AIL766iu/9bfffruQJEns37/fV0N0dPRp369Pnz5i8uTJp92HiEKDw0xE1Kjhw4fjvPPOwyuvvIJdu3YhJyfnlENMn3zyCUwmE6655hq/9TNnzgQAfPzxxwCATz/9FAAwffp0v/2mTZvm931tbS0+/vhjXHXVVTAajXC5XL5l4sSJqK2txc6dO0PRzAbt6NWrFwYPHtygHUIIfPLJJwCAwYMHo6ysDFOnTsV//vMfHD9+vMGxBg8ejA8//BD33Xcftm/fjpqampDXS0QeDDNE1ChJkvCXv/wFr7/+Ol544QV0794dl1xySaP7FhcXw2q1QpIkv/Xx8fHQaDS+oZXi4mJoNBrExcX57We1Whscz+Vy4Z///Ce0Wq3fMnHiRABoNEAEq7i4GImJiQ3WJyUl+bYDwA033IBXXnkFhw4dwtVXX434+Hikp6cjKyvL95pnn30W9957LzZt2oSRI0ciNjYWkydPxoEDB0JeN1FbxzBDRKc0c+ZMHD9+HC+88AL+8pe/nHK/uLg4/PHHHxBC+K0vKiqCy+VCu3btfPu5XK4G80YKCwv9vo+JiYFarcbMmTORk5PT6OINNaEUFxeHgoKCBuuPHj0KAL52AMBf/vIXZGdno7y8HJs3b4YQAldccQUOHToEADCZTHj44Yfx008/obCwEKtXr8bOnTsxadKkkNdN1NYxzBDRKXXo0AF/+9vfMGnSJMyYMeOU+40aNQqVlZXYtGmT3/pXX33Vtx0ARo4cCQB44403/PZbv3693/dGoxEjR47E999/j379+iEtLa3BcnLvTiiMGjUKe/fuxXfffdegHZIk+eqvz2QyYcKECVi8eDEcDgf27NnTYJ+EhATMnDkTU6dOxf79+1FdXR3y2onaMl7NRESn9fjjj59xnxtvvBHPPfccZsyYgd9++w19+/bF//73PyxduhQTJ07E6NGjAQBjx47FpZdeioULF6KqqgppaWn44osv8NprrzU45jPPPIOLL74Yl1xyCW6//XZ07twZFRUV+OWXX/B///d/vvkrTbVr1y688847DdYPGjQId911F1599VVcfvnleOSRR5CSkoLNmzfj+eefx+23347u3bsDAG655RYYDAYMGzYMiYmJKCwsxLJly2CxWDBo0CAAQHp6Oq644gr069cPMTEx2LdvH1577TUMGTIERqMxoNqJ6BQUnoBMRC1I/auZTufkq5mEEKK4uFjMnj1bJCYmCo1GI1JSUsSiRYtEbW2t335lZWVi1qxZIjo6WhiNRjFmzBjx008/NbiaSQjPFUizZs0SHTp0EFqtVrRv314MHTpUPProo377oAlXM51q8b7+0KFDYtq0aSIuLk5otVpx/vnni6eeekq43W7fsdatWydGjhwpEhIShE6nE0lJSeK6664TP/74o2+f++67T6SlpYmYmBih1+tFly5dxF133SWOHz9+2jqJqOkkIU4a5CYiIiIKI5wzQ0RERGGNYYaIiIjCGsMMERERhTWGGSIiIgprDDNEREQU1hhmiIiIKKy1+pvmybKMo0ePwmw2N3huDBEREbVMQghUVFQgKSkJKtXp+15afZg5evQokpOTlS6DiIiIApCfn4+OHTuedp9WH2bMZjMAz4cRFRWlcDVERER0Nmw2G5KTk32/x0+n1YcZ79BSVFQUwwwREVGYOZspIpwATERERGGNYYaIiIjCGsMMERERhbVWP2eGiIiCI8syHA6H0mVQK6PVaqFWq0NyLIYZIiI6JYfDgby8PMiyrHQp1ApFR0fDarUGfR84hhkiImqUEAIFBQVQq9VITk4+443LiM6WEALV1dUoKioCACQmJgZ1PIYZIiJqlMvlQnV1NZKSkmA0GpUuh1oZg8EAACgqKkJ8fHxQQ06M2URE1Ci32w0A0Ol0CldCrZU3JDudzqCOwzBDRESnxefa0bkSqp8thhkiIiIKawwzREREZzBixAgsWLBA6TLoFDgBmIiIWo0zDVvMmDEDa9eubfJx33vvPWi12gCr8pg5cybKysqwadOmoI5DDTHMBKii1onyGieMOg1iTZwcR0TUEhQUFPi+fuutt/DQQw9h//79vnXeK2i8nE7nWYWU2NjY0BVJIcdhpgC9+uUhXPzEp3jiw5+ULoWIiOpYrVbfYrFYIEmS7/va2lpER0fj3//+N0aMGIGIiAi8/vrrKC4uxtSpU9GxY0cYjUb07dsXb775pt9xTx5m6ty5M5YuXYpZs2bBbDajU6dOePHFF4OqfceOHRg8eDD0ej0SExNx3333weVy+ba/88476Nu3LwwGA+Li4jB69GhUVVUBALZv347BgwfDZDIhOjoaw4YNw6FDh4KqJ5wwzARIVdeVKQuhcCVERM1DCIFqh0uRRYTw/7X33nsv7rjjDuzbtw/jxo1DbW0tBg4ciP/+97/YvXs3br31Vtxwww346quvTnuc5cuXIy0tDd9//z3mzJmD22+/HT/9FNgfuL///jsmTpyIQYMG4YcffsDq1avx8ssv49FHHwXg6XGaOnUqZs2ahX379mH79u3IyMiAEAIulwuTJ0/G8OHD8eOPP+LLL7/Erbfe2qauQuMwU4BUdT8jboYZImojapxu9HroI0Xee+8j42DUheZX1oIFC5CRkeG37p577vF9PX/+fGzZsgVvv/020tPTT3mciRMnYs6cOQA8Aenpp5/G9u3b0aNHjybX9PzzzyM5ORmrVq2CJEno0aMHjh49invvvRcPPfQQCgoK4HK5kJGRgZSUFABA3759AQAlJSUoLy/HFVdcgfPOOw8A0LNnzybXEM7YMxMgdV2aYZYhIgovaWlpft+73W489thj6NevH+Li4hAZGYmtW7fi8OHDpz1Ov379fF97h7O8t+dvqn379mHIkCF+vSnDhg1DZWUljhw5gv79+2PUqFHo27cvrr32Wrz00ksoLS0F4JnPM3PmTIwbNw6TJk3CM8884zd3qC1gz0yAJA4zEVEbY9CqsfeRcYq9d6iYTCa/75cvX46nn34aK1euRN++fWEymbBgwYIzPin85InDkiQF/EBOIUSDYSHv0JokSVCr1cjKykJ2dja2bt2Kf/7zn1i8eDG++uorpKamYs2aNbjjjjuwZcsWvPXWW3jggQeQlZWFiy66KKB6wg17ZgLkG2aSGWaIqG2QJAlGnUaR5VzO//j8889x5ZVX4vrrr0f//v3RpUsXHDhw4Jy9X2N69eqF7Oxsv7lB2dnZMJvN6NChAwDP5z9s2DA8/PDD+P7776HT6bBx40bf/gMGDMCiRYuQnZ2NPn36YP369c3aBiWxZyZAHGYiImodunbtinfffRfZ2dmIiYnBihUrUFhYeE7mnZSXlyM3N9dvXWxsLObMmYOVK1di/vz5mDdvHvbv348lS5bg7rvvhkqlwldffYWPP/4YY8eORXx8PL766iscO3YMPXv2RF5eHl588UX86U9/QlJSEvbv34+ff/4ZN954Y8jrb6kYZgLEYSYiotbhwQcfRF5eHsaNGwej0Yhbb70VkydPRnl5ecjfa/v27RgwYIDfOu+N/D744AP87W9/Q//+/REbG4ubbroJDzzwAAAgKioKn332GVauXAmbzYaUlBQsX74cEyZMwB9//IGffvoJ69atQ3FxMRITEzFv3jzcdtttIa+/pZJEKK93a4FsNhssFgvKy8sRFRUVsuO+8dUhLN64G2N7JeDFG9PO/AIiojBTW1uLvLw8pKamIiIiQulyqBU63c9YU35/c85MgNS+nhmFCyEiImrjGGYC5L1pXivv2CIiImrxGGYCJPGmeURERC0Cw0yAvFczcZiJiIhIWQwzAeIwExERUcvAMBMgiTfNIyIiahEYZgJ0YpiJYYaIiEhJDDMBUvHSbCIiohaBYSZA3mczyUwzREREilI0zHTu3BmSJDVY5s6dC8AzuTYzMxNJSUkwGAwYMWIE9uzZo2TJPnycARFR6zVixAgsWLDA933nzp2xcuXK075GkiRs2rQp6PcO1XHaEkXDTE5ODgoKCnxLVlYWAODaa68FADz55JNYsWIFVq1ahZycHFitVowZMwYVFRVKlg2AdwAmImqJJk2ahNGjRze67csvv4QkSfjuu++afNycnBzceuutwZbnJzMzExdccEGD9QUFBZgwYUJI3+tka9euRXR09Dl9j+akaJhp3749rFarb/nvf/+L8847D8OHD4cQAitXrsTixYuRkZGBPn36YN26daiurm4RjzVX1X1y7JkhImo5brrpJnzyySc4dOhQg22vvPIKLrjgAlx44YVNPm779u1hNBpDUeIZWa1W6PX6Znmv1qLFzJlxOBx4/fXXMWvWLEiShLy8PBQWFmLs2LG+ffR6PYYPH47s7OxTHsdut8Nms/kt5wKHmYiIWp4rrrgC8fHxWLt2rd/66upqvPXWW7jppptQXFyMqVOnomPHjjAajejbty/efPPN0x735GGmAwcO4NJLL0VERAR69erlG1mo795770X37t1hNBrRpUsXPPjgg3A6nQA8PSMPP/wwfvjhB98UC2/NJw8z7dq1C5dddhkMBgPi4uJw6623orKy0rd95syZmDx5Mv7xj38gMTERcXFxmDt3ru+9AnH48GFceeWViIyMRFRUFK677jr88ccfvu0//PADRo4cCbPZjKioKAwcOBDffPMNAODQoUOYNGkSYmJiYDKZ0Lt3b3zwwQcB13I2NOf06E2wadMmlJWVYebMmQCAwsJCAEBCQoLffgkJCY0mbq9ly5bh4YcfPmd1evmGmeRz/lZERC2DEICzWpn31hpP3ODrNDQaDW688UasXbsWDz30kO8Pz7fffhsOhwPTp09HdXU1Bg4ciHvvvRdRUVHYvHkzbrjhBnTp0gXp6elnfA9ZlpGRkYF27dph586dsNlsfvNrvMxmM9auXYukpCTs2rULt9xyC8xmMxYuXIgpU6Zg9+7d2LJlC7Zt2wYAsFgsDY5RXV2N8ePH46KLLkJOTg6Kiopw8803Y968eX6B7dNPP0ViYiI+/fRT/PLLL5gyZQouuOAC3HLLLWdsz8mEEJg8eTJMJhN27NgBl8uFOXPmYMqUKdi+fTsAYPr06RgwYABWr14NtVqN3NxcaLVaAMDcuXPhcDjw2WefwWQyYe/evYiMjGxyHU3RYsLMyy+/jAkTJiApKclvvXTSD68QosG6+hYtWoS7777b973NZkNycnJoi0X9S7PZM0NEbYSzGliadOb9zoX7jwI601ntOmvWLDz11FPYvn07Ro4cCcAzxJSRkYGYmBjExMTgnnvu8e0/f/58bNmyBW+//fZZhZlt27Zh3759+O2339CxY0cAwNKlSxvMc3nggQd8X3fu3Bl//etf8dZbb2HhwoUwGAyIjIyERqOB1Wo95Xu98cYbqKmpwauvvgqTydP+VatWYdKkSXjiiSd8f/DHxMRg1apVUKvV6NGjBy6//HJ8/PHHAYWZbdu24ccff0ReXp7v9+drr72G3r17IycnB4MGDcLhw4fxt7/9DT169AAAdOvWzff6w4cP4+qrr0bfvn0BAF26dGlyDU3VIoaZDh06hG3btuHmm2/2rfOeXG8PjVdRUVGD3pr69Ho9oqKi/JZzwXdpNsMMEVGL0qNHDwwdOhSvvPIKAODgwYP4/PPPMWvWLACA2+3GY489hn79+iEuLg6RkZHYunUrDh8+fFbH37dvHzp16uQLMgAwZMiQBvu98847uPjii2G1WhEZGYkHH3zwrN+j/nv179/fF2QAYNiwYZBlGfv37/et6927N9Rqte/7xMREFBUVNem96r9ncnKyX0dAr169EB0djX379gEA7r77btx8880YPXo0Hn/8cRw8eNC37x133IFHH30Uw4YNw5IlS/Djjz8GVEdTtIiemTVr1iA+Ph6XX365b11qaiqsViuysrIwYMAAAJ55NTt27MATTzyhVKk+Kj5okojaGq3R00Oi1Hs3wU033YR58+bhueeew5o1a5CSkoJRo0YBAJYvX46nn34aK1euRN++fWEymbBgwQI4HI6zOnZjz+Q7ecRg586d+POf/4yHH34Y48aNg8ViwYYNG7B8+fImteN0oxH113uHeOpvkwOcB3Gq96y/PjMzE9OmTcPmzZvx4YcfYsmSJdiwYQOuuuoq3HzzzRg3bhw2b96MrVu3YtmyZVi+fDnmz58fUD1nQ/GeGVmWsWbNGsyYMQMazYlsJUkSFixYgKVLl2Ljxo3YvXs3Zs6cCaPRiGnTpilYsYdvmIlphojaCknyDPUosZzFfJn6rrvuOqjVaqxfvx7r1q3DX/7yF98v4s8//xxXXnklrr/+evTv3x9dunTBgQMHzvrYvXr1wuHDh3H06Ilg9+WXX/rt88UXXyAlJQWLFy9GWloaunXr1mC+p06ng9vtPuN75ebmoqqqyu/YKpUK3bt3P+uam8Lbvvz8fN+6vXv3ory8HD179vSt6969O+666y5s3boVGRkZWLNmjW9bcnIyZs+ejffeew9//etf8dJLL52TWr0U75nZtm0bDh8+7Ov+q2/hwoWoqanBnDlzUFpaivT0dGzduhVms1mBSv1xmImIqOWKjIzElClTcP/996O8vNx3cQkAdO3aFe+++y6ys7MRExODFStWoLCw0O8X9emMHj0a559/Pm688UYsX74cNpsNixcv9tuna9euOHz4MDZs2IBBgwZh8+bN2Lhxo98+nTt3Rl5eHnJzc9GxY0eYzeYGl2RPnz4dS5YswYwZM5CZmYljx45h/vz5uOGGG0475eJsuN1u5Obm+q3T6XQYPXo0+vXrh+nTp2PlypW+CcDDhw9HWloaampq8Le//Q3XXHMNUlNTceTIEeTk5ODqq68GACxYsAATJkxA9+7dUVpaik8++eSsP9tAKd4zM3bsWAghGk2YkiQhMzMTBQUFqK2txY4dO9CnTx8FqmyIw0xERC3bTTfdhNLSUowePRqdOnXyrX/wwQdx4YUXYty4cRgxYgSsVismT5581sdVqVTYuHEj7HY7Bg8ejJtvvhmPPfaY3z5XXnkl7rrrLsybNw8XXHABsrOz8eCDD/rtc/XVV2P8+PEYOXIk2rdv3+jl4UajER999BFKSkowaNAgXHPNNRg1ahRWrVrVtA+jEZWVlRgwYIDfMnHiRN+l4TExMbj00ksxevRodOnSBW+99RYAQK1Wo7i4GDfeeCO6d++O6667DhMmTPBdSex2uzF37lz07NkT48ePx/nnn4/nn38+6HpPRxKNDf61IjabDRaLBeXl5SGdDJybX4bJz32BDtEGfHHfZSE7LhFRS1FbW4u8vDykpqYiIiJC6XKoFTrdz1hTfn8r3jMTrrzDTK08CxIREbV4DDMBUvHZTERERC0Cw0yAvGHGzZ4ZIiIiRTHMBMj7oEkOMxERESmLYSZAag4zEVEbwT/a6FwJ1c8Ww0yAvDdfcjPNEFEr5b09/tneGZeoqaqrPQ8uPfkOxk2l+E3zwhVvmkdErZ1Go4HRaMSxY8eg1WqhUvHvXwoNIQSqq6tRVFSE6Ohov+dKBYJhJkDqujTDLENErZUkSUhMTEReXl6DW/EThUJ0dPRpnxp+thhmAqTiMBMRtQE6nQ7dunXjUBOFnFarDbpHxothJkASh5mIqI1QqVS8AzC1aBwADRCHmYiIiFoGhpkA8aZ5RERELQPDTIA4zERERNQyMMwEyNszIwRvKEVERKQkTgAOkGHPBryvexpZ7oGQxUSoJaUrIiIiapvYMxMgddUx9FPlIVk6xqEmIiIiBTHMBKruaiaVJBhmiIiIFMQwEyBJ5RmhkyDz8mwiIiIFMcwESKp7RokKgncBJiIiUhDDTIAk6USY4TATERGRchhmAqRSeZ4noYYMdswQEREph2EmQN5hJgkyZKYZIiIixTDMBEiq65nhMBMREZGyGGYC5D9nRuFiiIiI2jCGmUBxAjAREVGLwDATKF+YkRlmiIiIFMQwEyjfnBlezURERKQkhplA1R9mYpohIiJSDMNMoCTvpdmcM0NERKQkhplA1YUZ3jSPiIhIWQwzgZLqnprNZzMREREpimEmUFLdBGBJhuAwExERkWIYZgLlN2dG4VqIiIjaMMXDzO+//47rr78ecXFxMBqNuOCCC/Dtt9/6tgshkJmZiaSkJBgMBowYMQJ79uxRsOI69a5m4jATERGRchQNM6WlpRg2bBi0Wi0+/PBD7N27F8uXL0d0dLRvnyeffBIrVqzAqlWrkJOTA6vVijFjxqCiokK5woGTJgAzzBARESlFo+SbP/HEE0hOTsaaNWt86zp37uz7WgiBlStXYvHixcjIyAAArFu3DgkJCVi/fj1uu+225i75BOnEU7OZZYiIiJSjaM/M+++/j7S0NFx77bWIj4/HgAED8NJLL/m25+XlobCwEGPHjvWt0+v1GD58OLKzsxs9pt1uh81m81vOiXpPzXYzzRARESlG0TDz66+/YvXq1ejWrRs++ugjzJ49G3fccQdeffVVAEBhYSEAICEhwe91CQkJvm0nW7ZsGSwWi29JTk4+N8XXuzSbw0xERETKUTTMyLKMCy+8EEuXLsWAAQNw22234ZZbbsHq1av99pPqgoOXEKLBOq9FixahvLzct+Tn55+b4uvNmeGl2URERMpRNMwkJiaiV69efut69uyJw4cPAwCsVisANOiFKSoqatBb46XX6xEVFeW3nBP1Ls12y+fmLYiIiOjMFA0zw4YNw/79+/3W/fzzz0hJSQEApKamwmq1Iisry7fd4XBgx44dGDp0aLPW2oDv0mxezURERKQkRa9muuuuuzB06FAsXboU1113Hb7++mu8+OKLePHFFwF4hpcWLFiApUuXolu3bujWrRuWLl0Ko9GIadOmKVn6iTsAc84MERGRohQNM4MGDcLGjRuxaNEiPPLII0hNTcXKlSsxffp03z4LFy5ETU0N5syZg9LSUqSnp2Pr1q0wm80KVg7/OwBzmImIiEgxkmjls1dtNhssFgvKy8tDO3/m8FfAK2Pxm5yAw9d/gUu7tw/dsYmIiNq4pvz+VvxxBmGLc2aIiIhaBIaZQKnqwozEOTNERERKYpgJFOfMEBERtQgMM4Gq99Rs9swQEREph2EmUHxqNhERUYvAMBOoek/NlplliIiIFMMwEyjeNI+IiKhFYJgJVL05M252zRARESmGYSZQfk/NVrgWIiKiNoxhJlCS5PmHw0xERESKYpgJVL07AHOYiYiISDkMM4FSnZgAzI4ZIiIi5TDMBIo3zSMiImoRGGYCVX+YiWGGiIhIMQwzgfJ7arbCtRAREbVhDDOB8l6aLQkI9swQEREphmEmUHV3AAYAt5uPzSYiIlIKw0yg6u4zAwBCditYCBERUdvGMBMoqd5HJ9gzQ0REpBSGmUDVCzOymz0zRERESmGYCZTqxJwZwZ4ZIiIixTDMBKpezwzDDBERkXIYZgJVP8xwmImIiEgxDDOBYs8MERFRi8AwE6j6YYaXZhMRESmGYSZQ7JkhIiJqERhmAiVJEKi7cR57ZoiIiBTDMBMEUffxsWeGiIhIOQwzQRB1jzQQMsMMERGRUhhmguDrmeEwExERkWIYZoIgS95hJqFwJURERG0Xw0xQ6j4+4VK2DCIiojaMYSYIvjkzbs6ZISIiUgrDTBCEr2eGYYaIiEgpioaZzMxMSJLkt1itVt92IQQyMzORlJQEg8GAESNGYM+ePQpW7E9IvDSbiIhIaYr3zPTu3RsFBQW+ZdeuXb5tTz75JFasWIFVq1YhJycHVqsVY8aMQUVFhYIVn8AwQ0REpDzFw4xGo4HVavUt7du3B+DplVm5ciUWL16MjIwM9OnTB+vWrUN1dTXWr1+vcNVedR8fL80mIiJSjOJh5sCBA0hKSkJqair+/Oc/49dffwUA5OXlobCwEGPHjvXtq9frMXz4cGRnZ5/yeHa7HTabzW85V7wTgMGb5hERESlG0TCTnp6OV199FR999BFeeuklFBYWYujQoSguLkZhYSEAICEhwe81CQkJvm2NWbZsGSwWi29JTk4+Z/V7h5lkDjMREREpRtEwM2HCBFx99dXo27cvRo8ejc2bNwMA1q1b59tH8vZ+1BFCNFhX36JFi1BeXu5b8vPzz03xOHE1k8QwQ0REpBjFh5nqM5lM6Nu3Lw4cOOC7qunkXpiioqIGvTX16fV6REVF+S3njOS9NJtzZoiIiJTSosKM3W7Hvn37kJiYiNTUVFitVmRlZfm2OxwO7NixA0OHDlWwyhN8VzNxzgwREZFiNEq++T333INJkyahU6dOKCoqwqOPPgqbzYYZM2ZAkiQsWLAAS5cuRbdu3dCtWzcsXboURqMR06ZNU7LsEyTeNI+IiEhpioaZI0eOYOrUqTh+/Djat2+Piy66CDt37kRKSgoAYOHChaipqcGcOXNQWlqK9PR0bN26FWazWcmyfQTq5u4wzBARESlG0TCzYcOG026XJAmZmZnIzMxsnoKaSEhqz78cZiIiIlJMi5ozE3Y4zERERKQ4hplgeC8R59VMREREimGYCQKfzURERKQ8hpmg8NJsIiIipTHMBEPl+fhU7JkhIiJSDMNMMDjMREREpDiGmWAwzBARESmOYSYY3kuzZV7NREREpBSGmWCwZ4aIiEhxDDPBqLsDsMQwQ0REpBiGmWDwDsBERESKY5gJBsMMERGR4hhmgiHxqdlERERKY5gJhopPzSYiIlIaw0ww6oaZJPDSbCIiIqUwzARB8oYZIRSuhIiIqO1imAkG7zNDRESkOIaZYPjuAMwwQ0REpBSGmWDUTQDmnBkiIiLlMMwEQWLPDBERkeIYZoKh8n58DDNERERKYZgJAq9mIiIiUh7DTBCkugdN8g7AREREymGYCYbK2zPDMENERKQUhpkgSCo+aJKIiEhpDDPB4DATERGR4hhmguDtmZF4NRMREZFiGGaCcOJqJoYZIiIipTDMBEHy3QGYYYaIiEgpDDNBODHMJCDLvNcMERGREhhmguAdZlJBwM0b5xERESmCYSYYdcNMKshws2eGiIhIEQwzQVDVhRk1BGT2zBARESmCYSYI9S/NZs8MERGRMlpMmFm2bBkkScKCBQt864QQyMzMRFJSEgwGA0aMGIE9e/YoV+RJ6s+ZYZYhIiJSRosIMzk5OXjxxRfRr18/v/VPPvkkVqxYgVWrViEnJwdWqxVjxoxBRUWFQpX6k3xzZng1ExERkVIUDzOVlZWYPn06XnrpJcTExPjWCyGwcuVKLF68GBkZGejTpw/WrVuH6upqrF+/XsGKTzjRMyPzaiYiIiKFKB5m5s6di8svvxyjR4/2W5+Xl4fCwkKMHTvWt06v12P48OHIzs4+5fHsdjtsNpvfcq5I9a5mYs8MERGRMgIKM/n5+Thy5Ijv+6+//hoLFizAiy++2KTjbNiwAd999x2WLVvWYFthYSEAICEhwW99QkKCb1tjli1bBovF4luSk5ObVFOT8D4zREREigsozEybNg2ffvopAE/oGDNmDL7++mvcf//9eOSRR87qGPn5+bjzzjvx+uuvIyIi4pT7SZLk970QosG6+hYtWoTy8nLfkp+ff1b1BKR+mGHPDBERkSICCjO7d+/G4MGDAQD//ve/0adPH2RnZ2P9+vVYu3btWR3j22+/RVFREQYOHAiNRgONRoMdO3bg2WefhUaj8fXInNwLU1RU1KC3pj69Xo+oqCi/5ZyRTlyazY4ZIiIiZQQUZpxOJ/R6PQBg27Zt+NOf/gQA6NGjBwoKCs7qGKNGjcKuXbuQm5vrW9LS0jB9+nTk5uaiS5cusFqtyMrK8r3G4XBgx44dGDp0aCBlh15dD5GaPTNERESK0QTyot69e+OFF17A5ZdfjqysLPz9738HABw9ehRxcXFndQyz2Yw+ffr4rTOZTIiLi/OtX7BgAZYuXYpu3bqhW7duWLp0KYxGI6ZNmxZI2aFX/3EG7JohIiJSREBh5oknnsBVV12Fp556CjNmzED//v0BAO+//75v+CkUFi5ciJqaGsyZMwelpaVIT0/H1q1bYTabQ/YeQfHOmZF4nxkiIiKlSEIE1qXgdrths9n87g3z22+/wWg0Ij4+PmQFBstms8FisaC8vDz082ey/wlsfQDvuS9Gr7lvoof1HM7PISIiakOa8vs7oDkzNTU1sNvtviBz6NAhrFy5Evv3729RQeacq3/TPPbMEBERKSKgMHPllVfi1VdfBQCUlZUhPT0dy5cvx+TJk7F69eqQFtii1YUZNa9mIiIiUkxAYea7777DJZdcAgB45513kJCQgEOHDuHVV1/Fs88+G9ICWzTJMwFY4tVMREREigkozFRXV/sm4W7duhUZGRlQqVS46KKLcOjQoZAW2KLVXZrNOwATEREpJ6Aw07VrV2zatAn5+fn46KOPfM9PKioqOrc3qWtp6t0BmFczERERKSOgMPPQQw/hnnvuQefOnTF48GAMGTIEgKeXZsCAASEtsEWrN2eGw0xERETKCOg+M9dccw0uvvhiFBQU+O4xA3ju6nvVVVeFrLgWT+WdM8Ob5hERESkloDADAFarFVarFUeOHIEkSejQoUNIb5gXFuoNMzHLEBERKSOgYSZZlvHII4/AYrEgJSUFnTp1QnR0NP7+979DluVQ19hycZiJiIhIcQH1zCxevBgvv/wyHn/8cQwbNgxCCHzxxRfIzMxEbW0tHnvssVDX2TKpPB+fCjJc7JohIiJSREBhZt26dfjXv/7le1o2APTv3x8dOnTAnDlz2k6YqeuZ0UCGgz0zREREighomKmkpAQ9evRosL5Hjx4oKSkJuqiw4e2ZkTjMREREpJSAwkz//v2xatWqButXrVqFfv36BV1U2KgLMxq4IXOYiYiISBEBDTM9+eSTuPzyy7Ft2zYMGTIEkiQhOzsb+fn5+OCDD0JdY8tVF2bUcMPdhuY9ExERtSQB9cwMHz4cP//8M6666iqUlZWhpKQEGRkZ2LNnD9asWRPqGlsuX8+MzJ4ZIiIihQR8n5mkpKQGE31/+OEHrFu3Dq+88krQhYWFupvmqTnMREREpJiAemaoTr2eGU4AJiIiUgbDTDDq9cwwzBARESmDYSYYvgnAnDNDRESklCbNmcnIyDjt9rKysmBqCT/enhlJ5tVMRERECmlSmLFYLGfcfuONNwZVUFjhfWaIiIgU16Qw06Yuuz4b9e4zwzBDRESkDM6ZCQavZiIiIlIcw0ww/O4AzDBDRESkBIaZYNR7ajaHmYiIiJTBMBOMepdm82omIiIiZTDMBIMTgImIiBTHMBMM7wRgSYbMrhkiIiJFMMwEo+6meQAgC5eChRAREbVdDDPBUNW7TY+bYYaIiEgJDDPBqBdmhMwwQ0REpASGmWDUG2YSnDNDRESkCIaZYNTrmZHYM0NERKQIhplgSCc+Pg4zERERKUPRMLN69Wr069cPUVFRiIqKwpAhQ/Dhhx/6tgshkJmZiaSkJBgMBowYMQJ79uxRsOKTSBLckmeoiWGGiIhIGYqGmY4dO+Lxxx/HN998g2+++QaXXXYZrrzySl9gefLJJ7FixQqsWrUKOTk5sFqtGDNmDCoqKpQs248s1Q01McwQEREpQtEwM2nSJEycOBHdu3dH9+7d8dhjjyEyMhI7d+6EEAIrV67E4sWLkZGRgT59+mDdunWorq7G+vXrlSzbj0DdJGCGGSIiIkW0mDkzbrcbGzZsQFVVFYYMGYK8vDwUFhZi7Nixvn30ej2GDx+O7OzsUx7HbrfDZrP5LeeSXHdFk3C7z+n7EBERUeMUDzO7du1CZGQk9Ho9Zs+ejY0bN6JXr14oLCwEACQkJPjtn5CQ4NvWmGXLlsFisfiW5OTkc1q/qJszI/EOwERERIpQPMycf/75yM3Nxc6dO3H77bdjxowZ2Lt3r2+7JEl++wshGqyrb9GiRSgvL/ct+fn556x2oP4wE3tmiIiIlKA58y7nlk6nQ9euXQEAaWlpyMnJwTPPPIN7770XAFBYWIjExETf/kVFRQ16a+rT6/XQ6/Xntuh6fMNMnDNDRESkCMV7Zk4mhIDdbkdqaiqsViuysrJ82xwOB3bs2IGhQ4cqWKE/3zATwwwREZEiFO2Zuf/++zFhwgQkJyejoqICGzZswPbt27FlyxZIkoQFCxZg6dKl6NatG7p164alS5fCaDRi2rRpSpbtR3gvzRYcZiIiIlKComHmjz/+wA033ICCggJYLBb069cPW7ZswZgxYwAACxcuRE1NDebMmYPS0lKkp6dj69atMJvNSpbthz0zREREylI0zLz88sun3S5JEjIzM5GZmdk8BQVAeB826WaYISIiUkKLmzMTbmQOMxERESmKYSZYdQ+blBhmiIiIFMEwEySh4rOZiIiIlMQwE6QTdwBmzwwREZESGGaCVdczI/EOwERERIpgmAmS8IUZDjMREREpgWEmSN5hJl7NREREpAyGmWDV9cyoGGaIiIgUwTATLN+l2RxmIiIiUgLDTLC8c2bYM0NERKQIhplg8WomIiIiRTHMBEmwZ4aIiEhRDDNBkuoeNKninBkiIiJFMMwEy/c4A/bMEBERKYFhJkiSWuv5gsNMREREimCYCZJKzQdNEhERKYlhJkgqdd2DJhlmiIiIFMEwEyRfzwyHmYiIiBTBMBMk75wZ9swQEREpg2EmSGo17zNDRESkJIaZIKk0dT0zQoZbFgpXQ0RE1PYwzARJVTfMpIEbTrescDVERERtD8NMkNQazzCTmmGGiIhIEQwzQVLV3QFYAxlON4eZiIiImhvDTJC8l2arJTccLvbMEBERNTeGmWD59cwwzBARETU3hplgqU7MmXEwzBARETU7hplgqTyPM1CzZ4aIiEgRDDPBqj/M5OIEYCIioubGMBMsDjMREREpimEmWHXDTBrwaiYiIiIlMMwEy9czwzkzRERESmCYCZa3Z0biHYCJiIiUwDATrLqeGRV7ZoiIiBShaJhZtmwZBg0aBLPZjPj4eEyePBn79+/320cIgczMTCQlJcFgMGDEiBHYs2ePQhU3ot7VTA4+zoCIiKjZKRpmduzYgblz52Lnzp3IysqCy+XC2LFjUVVV5dvnySefxIoVK7Bq1Srk5OTAarVizJgxqKioULDyeupdzeTkBGAiIqJmp1Hyzbds2eL3/Zo1axAfH49vv/0Wl156KYQQWLlyJRYvXoyMjAwAwLp165CQkID169fjtttuU6Jsf3VzZrS8NJuIiEgRLWrOTHl5OQAgNjYWAJCXl4fCwkKMHTvWt49er8fw4cORnZ3d6DHsdjtsNpvfck6p9QAAHZycM0NERKSAFhNmhBC4++67cfHFF6NPnz4AgMLCQgBAQkKC374JCQm+bSdbtmwZLBaLb0lOTj63heuMAACDZOd9ZoiIiBTQYsLMvHnz8OOPP+LNN99ssE2SJL/vhRAN1nktWrQI5eXlviU/P/+c1OujNQEAjLDDyQnAREREzU7ROTNe8+fPx/vvv4/PPvsMHTt29K23Wq0APD00iYmJvvVFRUUNemu89Ho99Hr9uS24Pm/PDOwcZiIiIlKAoj0zQgjMmzcP7733Hj755BOkpqb6bU9NTYXVakVWVpZvncPhwI4dOzB06NDmLrdxWk+Y0UsuuFwOhYshIiJqexTtmZk7dy7Wr1+P//znPzCbzb55MBaLBQaDAZIkYcGCBVi6dCm6deuGbt26YenSpTAajZg2bZqSpZ9QF2YAAPZq5eogIiJqoxQNM6tXrwYAjBgxwm/9mjVrMHPmTADAwoULUVNTgzlz5qC0tBTp6enYunUrzGZzM1d7Cho9ZKigggzhrDrz/kRERBRSioYZIc48YVaSJGRmZiIzM/PcFxQISYJTbYDeXQWViz0zREREza3FXM0UzlzqCACA5KhVuBIiIqK2h2EmBFxqz7wZ9swQERE1P4aZEHCrDQAYZoiIiJTAMBMCbg3DDBERkVIYZkJArgszaleNwpUQERG1PQwzIeANMxo3wwwREVFzY5gJAVnjmQDMMENERNT8GGZCQNTdBVgjM8wQERE1N4aZUKgLMzr2zBARETU7hplQ0Hl7ZuwKF0JERNT2MMyEgs7k+YfDTERERM2OYSYEJO8wk8zHGRARETU3hpkQkOqGmfSCYYaIiKi5McyEgEofCQDQMcwQERE1O4aZEDBGmgEAerkWLrescDVERERtC8NMCJhMUQAAA+woq3EqXA0REVHbwjATAuoIzzCTEbUoqXIoXA0REVHbwjATCnVXMxklO8MMERFRM2OYCYXIeABALCpQVlGpcDFERERtC8NMKBjbwSlpoZIEakuOKF0NERFRm8IwEwoqFcq0CQAAueSwwsUQERG1LQwzIVJlSAIASBW/K1wJERFR28IwEyJ2YyIAQF/JMENERNScGGZCxBXVEQBgrDmqcCVERERtC8NMiKiiOwEAohx/KFwJERFR28IwEyLaWE+YaedimCEiImpODDMhYmifCgCIl48BMp/PRERE1FwYZkIkJrEzqoUeEZITtvwflS6HiIiozWCYCRGjwYBd6p4AgOJd2xSuhoiIqO1gmAmhI9FpAADVoc8VroSIiKjtYJgJIXvHiwEA8cXfALJb4WqIiIjaBoaZEIrrmgabMMIgVwK//U/pcoiIiNoEhpkQ6tEhFv91pwMA5O/fULgaIiKitoFhJoSSY4z4QDMKACD2/geotSlcERERUeunaJj57LPPMGnSJCQlJUGSJGzatMlvuxACmZmZSEpKgsFgwIgRI7Bnzx5lij0LKpWE5L6X4qCcCLW7FtizUemSiIiIWj1Fw0xVVRX69++PVatWNbr9ySefxIoVK7Bq1Srk5OTAarVizJgxqKioaOZKz951gzrhbfdwAIDrOw41ERERnWuKhpkJEybg0UcfRUZGRoNtQgisXLkSixcvRkZGBvr06YN169ahuroa69evV6Das3NBcjRyY8fBLSRofv8KOP6L0iURERG1ai12zkxeXh4KCwsxduxY3zq9Xo/hw4cjOzv7lK+z2+2w2Wx+S3OSJAlj0gdgh9zfsyKXvTNERETnUosNM4WFhQCAhIQEv/UJCQm+bY1ZtmwZLBaLb0lOTj6ndTbmqgEdsFGMAAA4v1/Pe84QERGdQy02zHhJkuT3vRCiwbr6Fi1ahPLyct+Sn59/rktsINakg6bnRJSKSGirCoGDnzZ7DURERG1Fiw0zVqsVABr0whQVFTXoralPr9cjKirKb1HCTSN64D/uoQCAqpzXFamBiIioLWixYSY1NRVWqxVZWVm+dQ6HAzt27MDQoUMVrOzs9OlgQV7SFQAA3S8fAPaWewUWERFROFM0zFRWViI3Nxe5ubkAPJN+c3NzcfjwYUiShAULFmDp0qXYuHEjdu/ejZkzZ8JoNGLatGlKln3WBg0bjYNyIrSy3XMTPSIiIgo5jZJv/s0332DkyJG+7++++24AwIwZM7B27VosXLgQNTU1mDNnDkpLS5Geno6tW7fCbDYrVXKTjOppxYu4FHfiLVR8/QaiBlyvdElEREStjiSEEEoXcS7ZbDZYLBaUl5crMn/mkdc+xEMH/wwZElR37QEsHZq9BiIionDTlN/fLXbOTGsx8qI0fCX3gAoCztwNSpdDRETU6jDMnGPDzmuHj3Weh086vnqF95whIiIKMYaZc0ylkmAZNBVlwgRT9RHgwFalSyIiImpVGGaaweT0rvi3ewQAoPazZ4DWPU2JiIioWTHMNIMO0Qbs7TQNdqFBxO9fAgc/UbokIiKiVoNhppmMHzoQr7vHAACcWQ+zd4aIiChEGGaaydheVmyPvwGVIgLaP34A9r2vdElEREStAsNMM1GpJCy4cihedk8AANg/ygSctcoWRURE1AowzDSjgSkxKOx1M4pENPTlv0L+5O9Kl0RERBT2GGaa2Z2Xp+Fh3AoAkL58DuJQtsIVERERhTeGmWZmtURg7FUz8W/XcEgQOPbaLDgqS5Uui4iIKGwxzCjgygs6oPqyv+N30Q7xrgIcXzsdcLuULouIiCgsMcwoZOZl/fHtRf9EjdAh6fgXcG19QOmSiIiIwhLDjILGjh6HR7R3AAA0X60Gsv+pcEVEREThh2FGQRFaNUZedQuedF7nWbH1AVRuf1bZooiIiMIMw4zCxva2wjlkAZ5xXQUAiNz+IPa99SCELCtcGRERUXhgmGkBFl/RG8NuWo4NEVMAAD33PYvvnr4aNVUVCldGRETU8jHMtBBpqXG4+m8v4JOu98Mp1BhY8QkOLx+OXfv2Kl0aERFRi8Yw04Jo1Spcdv29ODD+DZQiCufLB2HdMB67vvwIgg+mJCIiahTDTAvUa8gEqGdvx2FtKtpL5ei9ZQo+fGIafj/6u9KlERERtTgMMy1UlPU8tLtzO76OGgOVJDCx9gMYXkzH/615HJ/t/wMuNycIExERAYAkWvn4hc1mg8ViQXl5OaKiopQuJyAluz9GxcYFSHEfBgB8L3fF07pbcdnIsZh+UQq0amZSIiJqXZry+5thJky4nQ788t/lSNn1DCLkGshCQpY8EB9EZiCu5wj8aUAHXJAcrXSZREREIcEwU09rCTM+tgK4P3oA6j3v+FbtlHviWfc16D1kAq4c0BFd2ptQUetCQlSEgoUSEREFjmGmnlYXZryKfoIj+3moftwAjWwHAByS47FRvgRZ2pHYVxuLawcm44YhKThSWo3h3eNh0KkVLpqIiOjsMMzU02rDjFdZPsRnT8H14zvQuqp8q79098K78iX4wJ2OakQgxqhFD2sUrk3riIwLOypYMBER0ZkxzNTT6sOMl6MaYt//4dj/1qD9sZ2Q4DmtVUKPLfJgvOO+FDny+XBBA4tBi0RLBBxuGRaDFgvH9cCQ8+IUbgAREdEJDDP1tJkwU1/5EeCHDUDueqDkoG+1Azr8z90LH8qD8ZE7DTZE+raltjMhyqDFJV3b4fJ+iehhNUOSJCWqJyIiYpipr02GGS8hgPyvgR/WA3s2AbVlvk2ypEF5+zTk4ny8cdSKr13n+YWbLu1MSI41Ym+BDZ3jjJjYNxHx5gikd4mFVqWCOUIDlYphh4iIzg2GmXradJipTwjg2E/Avv/zBJuiPQ12sZnPQy7OxwdlnfCVqxvyhBVA44FFo5KQEBWBvwzrjD/1T8Lb3x6BTq3Cny5I8ruKSggBlyx4LxwiImoShpl6GGZO4fgvwKH/eXpuDu/0G47ysmujURo3ALsdVuxzJWG7qw++LdHhVAEHAFQS0MMahRiTFhaDFvklNdj1ezmGd2+P69KS0a+jBVEGLb48WAy3LNC3gwUJFj30Gl5pRUREJzDM1MMwc5aqjnuCTf5Xnn+Pfge4ahvsJgyxEO3OR010N+xzJWHNzzr8UB0HY7tOiDJG4JtDpU1+a71GhaHnxcFi0OLgsSp0bmdCvFkPk06Nogo7OsYYMDAlFhq1hFiTDrVON2qdbvTrGA2HS0aEVg01h7yIiFoVhpl6GGYC5HIAhbs84ab0N+BwNlC4G0DjPy5CpYFk6YjayGSU6JJQqkvEcY0VlcaO6Ny1Fzbtr8XnvxTj12NVcLhlJFkiYDHq8OuxSthdgT1nSq9Rwe6SoVZ5Qo7TLUNT93WsSQeTToNalxtCAOdbzeiVGAVZCJRVO2HUazxDbwAq7C78XlqDhKgIdI2PRH5JNX4rrsJ57SMRHxWBDtERiDPp4XDLiDHqIEnAL0WVSIkzwqBVw2LQQgjAVuuESa+BWxYQAryvDxFREBhm6mGYCSFHNVB8ADi23zP/5th+z1J2CHA7Tv9atQ6ItEKYrXAb20NtjodkagdhbIcjThP2lOlxTI6CNbEjfq1Uo9QuodLuRLRBh5zfSnCswg6XLFBa7YBeo4ZbllFa7Wyedp+BQauGwy3DLQtEaFWQZUAWAt0SzHDLMuwuGXanjFqXG3anDIdbRu+kKFTaXTheYUd7sx7JsUZoVBK+yitBT2sUjHo1jpTWwOGS0bmdCTFGLarsbkgSoJYkqNUStCoJapUKWrUEIYDdR8sRF6lHu0gdyuo+m4paz79DusTBYtRBlgWOlFYj1qRHQXkNKuwuxJv1iDdHIDJCg9IqByrtLph0GlTanSipciIuUgeNSoJLFogx6pAUHYHiSgf2Fdig06hQXuNE3w4WxEfpcbSsFhaDFj2sZvxeVoODx6pgd7nROc4EvUYFlSRBFgIHj1UiISoCnWKN+MNWixqHG0a9BiadBpERGkRFaGDSa5BfUo0apxuReg2OVzpwrMKOGKMWqe1MUKkkGLRq5JdU43BJNZKiDTDq1IjQqiEEUFBeA1kImPQa/HqsCn07WhBv1kOjUiHveCXam/XoEG1EeY0TapUEtUrC4ZJqRBu0qHG6YdJpUFLtQJd2JnSMMQAA7C7Z99kW2moRbdAiLlIHo04DtUpCtcPl+5k4VmFHpd2FznEm1LrckCBhz9FydIozItqgg0uW4XQLuNwyXLJAhFaNqAgN7HW9jQDgcsv4vawGsSYdIrRqlNc44XDJcLhkSBKQFG2ARiXht+JqVDs872XSawAAblnA6T5xLC8hBGw1LkACoiI0EAJwyZ5fAy5ZhlGn8du/oLwGURFaCABOl4wog9Y30Fxhd8GsP/3FALIsUOVwwRyhDfC/MGqrWl2Yef755/HUU0+hoKAAvXv3xsqVK3HJJZec1WsZZpqBLAMVBZ5QU/obUFr3b9khz9cVR5t+TLUeiIgC9FF1/5rrvrYA+ijIukgUuyJgssTCqYlEqdsAVYQZDo0ZJa4IFNfKqHHKUJti4HBL2Ftgw/7CCug1KkQbdaiodcH7/1+NWkKXdpE4UlqNg8eq0CnOiJRYI/YXVqDS7sIvRZWocbqhr/vFLQsg0RKBP2y1kFv8fz0UCpIEROo9QcNxip5EtUqCu+4HQpJ8HX++9SoJZ/x5MerUqHa4YTFo4a4LAUJ4jiHhROjw0qgkWAxaFFd5/pjQqVUw6NSQhUCNww2XLGDSqREZoYHDJUOvUaOk2uFrg8WghSwLVNhdvrqTLAYU2mrRMcYAh0tGQXkttGpPG7xvr5IAjVoFh8vTG9ouUo9Ykw6l1Q5EGz3hN7+0GnLd5P/iKgfiTDqY9Bpo1Z7gmF9SA51GhRijFipJgiQBKslzh6wahxt2lxtWSwSMWv9w1fgJ8tRUXuP577qgvBZCCBi0ariFQEqsCccr7TAbtDDrNThWYYfD3fA8miM06J1kgd3lRkWtC5W1Lhi9n6fTjRqHG1q1Cu3NeqgkCUfKauCq+0NGFsLvM/J+vu3NelTZXTDqNIjUq6FWqfDzHxWoqHUi2qjzhc6oCC2csoziSgcsBi26tDehyu6CSpJQXuPEsUo7zHoN4qMiUFrlQJXDjZ6JZug1Khz4oxJ5x6sQZdCiV2IUrHX/f6qqO68CQKxJh6NlNb6fJ7VKgiRJUEtAjdMNlSShY4wBGrUK+SXVsBi06JkYhR/yyxBj1EGvVcFW4/Rd0KFWSdCqVYgyeP4IGt0zAWN7W898rpqgVYWZt956CzfccAOef/55DBs2DP/v//0//Otf/8LevXvRqVOnM76eYaYFcDmAyj88gaeiAKg65pmjU3Wsbik+8XVNSWjfW1J5QpAQnlBkiAa0Rk9PkUbvCU0aHaCJqLfupG1qPSDcgKMKTqFGbWRHmCPNEGotnNCguAbQ6XSINEagqMoNtUYLWdKgsKgIRrcNckwqNDoj9Do1dBotBFTIziuBQadBr6RoFFe5sLewEserXLjk/Hj8XmaHUwaSYkyI0Gmw+/dyOOr+IhYCcMuev+Q9/xMUvu+7tI/E76U1cLplJETpAQDmCC1sNU7k/FYKlyxDCMBqicDxCjuijTp0iDGgqKIWx2yeXoQYow7mCA2qHC5E6jWINupwrMLzuAytWkJRhR1FNjsitCr06xgNIQQidGrk5JXA6RaIN+txpLQGf1TUIsaoQ8/EKOjUnh4P7y9iWQh0jDbi1+OVqKh1wWqJgEmvQbXdhSq7GxV2F2w1TlTUOpEUbYDFoEV5jROReg1S4kz4w1aL/NJqAECV3YUOMUYkxxiQX1INWXj+xyzB005ZCJRUOdGlvQn7CmyorHWh1ulGxxgjfi+rQZXdhSiDFnanG063QEqcERV1v8Aq7C6YIzT47XiV3y8oSfJMgY83R6C8xokap7vxHz0J0Nb9wveKNelQUtWwF/N0QUenVvn94tWpVdBrVHDKMmqdnvU6jQqRek2jxw5W/WBGdCqzh5+H+yb0COkxW1WYSU9Px4UXXojVq1f71vXs2ROTJ0/GsmXLzvh6hpkwI7sBewVgtwG1Ns+/9oq6r8sbWVd/v3pfi8Dm4bRIkuo0iwRI6jNsP2mdSn3qbU1aTnfsAI/vqgVK8jyhN7GfJ3jWlAIqDWCMBXRmT+CtLgbiugLqekMXQnj29a4TsieYVhcDhlhPmK21edbpjBBuF2A7AkmlhYjpDBmeYTtIEnxX7EkSqp0yXG6BKqcbapUa7UxayLIbGsiAsxquksNwRnh6CHV6PSSNHs6KYmjVgMrUDpU1tYjQquEuOQSTyQyHNgputR5qjQZq2QWVWg2V7ERNVQVsMMLsLoNNHQe1VgedVgNzhA7ltU4AEixGPVQqFQDPcF1ZZRVsldVIMmug1WpQXCPgFCqoVCpoNRrodRpU2t2occjQalRwuAUidWpE61wQUKGgUkClkhAbIUG4nXA5HThuq0K0QY1ShxbQR6JjXBQqal3QOctgkhywCw1k2Q2Xy4XIuCRUOoHyaidsNXZEO/9AmWyAQx+HhKgIqGqKIVcUoV1sNI7bNbCrDHDJniGw2Eg93LKMGocMAU+Y8/5XG6FRQ6WSUFLlPNEb5XcTT8/X3l9eAhJkAZj0aggAZr0WKpUKLlmG2y1wvMqBGKMONU4ZVQ43oo166LWen1Wh0kDlrITaWY1jNTKOlDuh0+lhiDAgQqeBXF0Co7MEam0EEJmAGpURZVV2uFwuJFr00KoE1BKghoBKElBLAipXLdwaAwqdRlTY3TBp1ahxyqhxumF3yegUa0SsSYeyikrohR1qrR6VLhW0rirEae2orihFcbkNUmQiDLUFkMyJiIjtgAqHQFmtgEkLGCQ7CorLUSUikNQuBsmxJlTWOrG/0Aab3YnoCK3nDyAAbhkoq3bCGm2AWuX5rGQh4BYSZFlAr9NA2KthKy6ApvY4rCYVDmrOw54iJ3rEGyC7nFDBDX2EETrJCclZAwd0qBFq1FZX4XzXT4g5/xL0G3RpSP/X15Tf32fRf6cch8OBb7/9Fvfdd5/f+rFjxyI7O7vR19jtdtjtdt/3NpvtnNZIIaZSe3pPDNGBH0MIzy8yIQPVJZ6bBUoqzy+ymhLAWeOZ4+OyA267p+fI7197ve11/6rUnl+szhrA9rtnvdtR9xoHIDs9QcztBGSX53tNBGCIAcoOe9Z5a2pq0ArkNa3B0e/O6eFP/tV4qunaxrp/6/+vtP5dkzR1i6HeOn29r2NOOp4ejTPUO4bxpG0nH8NbQ2zd4tWukf1Mp3g/AEhpZF10I8eq37aTZ76cXENjxwSAM/ejN5QawGuC0S3Ex+sZ4uOdjQtDdJx07xf5Z/mCRBlAaMNMU7ToMHP8+HG43W4kJCT4rU9ISEBhYWGjr1m2bBkefvjh5iiPWipvbwXUgDnBs7Q09QOXkD1BqP73Qm64j9/iPsP2Ro4RDu+h0gDRKYApDjj6vec8GqIBt8vTw+KsAnSRnp6Wst8aXlwXYTkxGV1SecKpsZ2nx6a23LNddgGOKs97RcZ7wmrFUf+xFCHgO7j36/rbvT1Qah1g6egJzc5qT4h1OTxzvABPkFbrPCE3JsXT81Rb7vne7fRsk12en1mdyVNnZIJnyFV21X023veX/b8GPEOgaq1nkd11obqRz9nTkBPt0Ro8/7pq6tqj9dSi1ni+llSe9thtJ44XYfG0S3Z6XiupgKoi/3NgtnrabK/wfK8zAVEdPO12VHvOX/3P1vf51q/P7z+Uk/ZpbN1pjnXyuvrn0vt5yk7P5xFh8fycyXXnxvsHiiEGMLWr+zkp9Hwufr2h8O9dhARoIwB7pefzO139mgjPvq66P4j05hPzA1VqwHYUMCd6eiprbXV/KHl/Xsye8+Ws8Xy2QF1Cl070YjX62Z7i89PoAVN7zyK76q5ehacOlcbzr6vW8/OhM9X9MVfraXNif6BdqKNg07ToMON18jOChBCnfG7QokWLcPfdd/u+t9lsSE5OPqf1ETVZ/cBFjetztdIVEFGYaNFhpl27dlCr1Q16YYqKihr01njp9Xro9afqyCUiIqLWpkU/MEen02HgwIHIysryW5+VlYWhQ4cqVBURERG1JC26ZwYA7r77btxwww1IS0vDkCFD8OKLL+Lw4cOYPXu20qURERFRC9Diw8yUKVNQXFyMRx55BAUFBejTpw8++OADpKScas48ERERtSUt/j4zweJ9ZoiIiMJPU35/t+g5M0RERERnwjBDREREYY1hhoiIiMIawwwRERGFNYYZIiIiCmsMM0RERBTWGGaIiIgorDHMEBERUVhjmCEiIqKw1uIfZxAs7w2ObTabwpUQERHR2fL+3j6bBxW0+jBTUVEBAEhOTla4EiIiImqqiooKWCyW0+7T6p/NJMsyjh49CrPZDEmSQnpsm82G5ORk5Ofnt7rnPrFt4YltC09sW3hqzW0DlG+fEAIVFRVISkqCSnX6WTGtvmdGpVKhY8eO5/Q9oqKiWuUPMsC2hSu2LTyxbeGpNbcNULZ9Z+qR8eIEYCIiIgprDDNEREQU1hhmgqDX67FkyRLo9XqlSwk5ti08sW3hiW0LT625bUB4ta/VTwAmIiKi1o09M0RERBTWGGaIiIgorDHMEBERUVhjmCEiIqKwxjAToOeffx6pqamIiIjAwIED8fnnnytdUpNlZmZCkiS/xWq1+rYLIZCZmYmkpCQYDAaMGDECe/bsUbDiU/vss88wadIkJCUlQZIkbNq0yW/72bTFbrdj/vz5aNeuHUwmE/70pz/hyJEjzdiKxp2pbTNnzmxwHi+66CK/fVpq25YtW4ZBgwbBbDYjPj4ekydPxv79+/32CddzdzZtC9dzt3r1avTr1893M7UhQ4bgww8/9G0P13MGnLlt4XrOGrNs2TJIkoQFCxb41oXtuRPUZBs2bBBarVa89NJLYu/eveLOO+8UJpNJHDp0SOnSmmTJkiWid+/eoqCgwLcUFRX5tj/++OPCbDaLd999V+zatUtMmTJFJCYmCpvNpmDVjfvggw/E4sWLxbvvvisAiI0bN/ptP5u2zJ49W3To0EFkZWWJ7777TowcOVL0799fuFyuZm6NvzO1bcaMGWL8+PF+57G4uNhvn5batnHjxok1a9aI3bt3i9zcXHH55ZeLTp06icrKSt8+4XruzqZt4Xru3n//fbF582axf/9+sX//fnH//fcLrVYrdu/eLYQI33MmxJnbFq7n7GRff/216Ny5s+jXr5+48847fevD9dwxzARg8ODBYvbs2X7revToIe677z6FKgrMkiVLRP/+/RvdJsuysFqt4vHHH/etq62tFRaLRbzwwgvNVGFgTv6FfzZtKSsrE1qtVmzYsMG3z++//y5UKpXYsmVLs9V+JqcKM1deeeUpXxMubRNCiKKiIgFA7NixQwjRus7dyW0TonWdu5iYGPGvf/2rVZ0zL2/bhGgd56yiokJ069ZNZGVlieHDh/vCTDifOw4zNZHD4cC3336LsWPH+q0fO3YssrOzFaoqcAcOHEBSUhJSU1Px5z//Gb/++isAIC8vD4WFhX7t1Ov1GD58eNi182za8u2338LpdPrtk5SUhD59+oRFe7dv3474+Hh0794dt9xyC4qKinzbwqlt5eXlAIDY2FgArevcndw2r3A/d263Gxs2bEBVVRWGDBnSqs7ZyW3zCvdzNnfuXFx++eUYPXq03/pwPnet/kGToXb8+HG43W4kJCT4rU9ISEBhYaFCVQUmPT0dr776Krp3744//vgDjz76KIYOHYo9e/b42tJYOw8dOqREuQE7m7YUFhZCp9MhJiamwT4t/bxOmDAB1157LVJSUpCXl4cHH3wQl112Gb799lvo9fqwaZsQAnfffTcuvvhi9OnTB0DrOXeNtQ0I73O3a9cuDBkyBLW1tYiMjMTGjRvRq1cv3y+0cD5np2obEN7nDAA2bNiA7777Djk5OQ22hfN/bwwzAZIkye97IUSDdS3dhAkTfF/37dsXQ4YMwXnnnYd169b5JrS1hnZ6BdKWcGjvlClTfF/36dMHaWlpSElJwebNm5GRkXHK17W0ts2bNw8//vgj/ve//zXYFu7n7lRtC+dzd/755yM3NxdlZWV49913MWPGDOzYscO3PZzP2ana1qtXr7A+Z/n5+bjzzjuxdetWREREnHK/cDx3HGZqonbt2kGtVjdIoEVFRQ3SbLgxmUzo27cvDhw44LuqqTW082zaYrVa4XA4UFpaesp9wkViYiJSUlJw4MABAOHRtvnz5+P999/Hp59+io4dO/rWt4Zzd6q2NSaczp1Op0PXrl2RlpaGZcuWoX///njmmWdaxTk7VdsaE07n7Ntvv0VRUREGDhwIjUYDjUaDHTt24Nlnn4VGo/HVF47njmGmiXQ6HQYOHIisrCy/9VlZWRg6dKhCVYWG3W7Hvn37kJiYiNTUVFitVr92OhwO7NixI+zaeTZtGThwILRard8+BQUF2L17d9i1t7i4GPn5+UhMTATQstsmhMC8efPw3nvv4ZNPPkFqaqrf9nA+d2dqW2PC6dydTAgBu90e1ufsVLxta0w4nbNRo0Zh165dyM3N9S1paWmYPn06cnNz0aVLl/A9d8084bhV8F6a/fLLL4u9e/eKBQsWCJPJJH777TelS2uSv/71r2L79u3i119/FTt37hRXXHGFMJvNvnY8/vjjwmKxiPfee0/s2rVLTJ06tcVeml1RUSG+//578f333wsAYsWKFeL777/3XS5/Nm2ZPXu26Nixo9i2bZv47rvvxGWXXab45YZCnL5tFRUV4q9//avIzs4WeXl54tNPPxVDhgwRHTp0CIu23X777cJisYjt27f7XepaXV3t2ydcz92Z2hbO527RokXis88+E3l5eeLHH38U999/v1CpVGLr1q1CiPA9Z0Kcvm3hfM5Opf7VTEKE77ljmAnQc889J1JSUoROpxMXXnih3+WW4cJ7/wCtViuSkpJERkaG2LNnj2+7LMtiyZIlwmq1Cr1eLy699FKxa9cuBSs+tU8//VQAaLDMmDFDCHF2bampqRHz5s0TsbGxwmAwiCuuuEIcPnxYgdb4O13bqqurxdixY0X79u2FVqsVnTp1EjNmzGhQd0ttW2PtAiDWrFnj2ydcz92Z2hbO527WrFm+//+1b99ejBo1yhdkhAjfcybE6dsWzufsVE4OM+F67iQhhGi+fiAiIiKi0OKcGSIiIgprDDNEREQU1hhmiIiIKKwxzBAREVFYY5ghIiKisMYwQ0RERGGNYYaIiIjCGsMMEbU5kiRh06ZNSpdBRCHCMENEzWrmzJmQJKnBMn78eKVLI6IwpVG6ACJqe8aPH481a9b4rdPr9QpVQ0Thjj0zRNTs9Ho9rFar3xITEwPAMwS0evVqTJgwAQaDAampqXj77bf9Xr9r1y5cdtllMBgMiIuLw6233orKykq/fV555RX07t0ber0eiYmJmDdvnt/248eP46qrroLRaES3bt3w/vvvn9tGE9E5wzBDRC3Ogw8+iKuvvho//PADrr/+ekydOhX79u0DAFRXV2P8+PGIiYlBTk4O3n77bWzbts0vrKxevRpz587Frbfeil27duH9999H165d/d7j4YcfxnXXXYcff/wREydOxPTp01FSUtKs7SSiEFH0MZdE1ObMmDFDqNVqYTKZ/JZHHnlECOF52vTs2bP9XpOeni5uv/12IYQQL774ooiJiRGVlZW+7Zs3bxYqlUoUFhYKIYRISkoSixcvPmUNAMQDDzzg+76yslJIkiQ+/PDDkLWTiJoP58wQUbMbOXIkVq9e7bcuNjbW9/WQIUP8tg0ZMgS5ubkAgH379qF///4wmUy+7cOGDYMsy9i/fz8kScLRo0cxatSo09bQr18/39cmkwlmsxlFRUWBNomIFMQwQ0TNzmQyNRj2ORNJkgAAQgjf143tYzAYzup4Wq22wWtlWW5STUTUMnDODBG1ODt37mzwfY8ePQAAvXr1Qm5uLqqqqnzbv/jiC6hUKnTv3h1msxmdO3fGxx9/3Kw1E5Fy2DNDRM3ObrejsLDQb51Go0G7du0AAG+//TbS0tJw8cUX44033sDXX3+Nl19+GQAwffp0LFmyBDNmzEBmZiaOHTuG+fPn44YbbkBCQgIAIDMzE7Nnz0Z8fDwmTJiAiooKfPHFF5g/f37zNpSImgXDDBE1uy1btiAxMdFv3fnnn4+ffvoJgOdKow0bNmDOnDmwWq1444030KtXLwCA0WjERx99hDvvvBODBg2C0WjE1VdfjRUrVviONWPGDNTW1uLpp5/GPffcg3bt2uGaa65pvgYSUbOShBBC6SKIiLwkScLGjRsxefJkpUshojDBOTNEREQU1hhmiIiIKKxxzgwRtSgc+SaipmLPDBEREYU1hhkiIiIKawwzREREFNYYZoiIiCisMcwQERFRWGOYISIiorDGMENERERhjWGGiIiIwhrDDBEREYW1/w+ZsquWKo4zBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "Mean Squared Error (MSE): 0.0769\n",
      "Root Mean Squared Error (RMSE): 0.2773\n",
      "R² Score: 0.9936\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MAE: 0.063\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 훈련 과정 시각화\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 성능 평가\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R² Score: {r2:.4f}')\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "error = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c16c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3517c9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad53d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
