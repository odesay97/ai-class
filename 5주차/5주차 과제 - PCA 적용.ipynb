{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74960e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Column information\n",
    "1)Pregnancies (임신횟수) =>Number of times pregnant\n",
    "\n",
    "2)Glucose (포도당) =>Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "\n",
    "3)BloodPressure (혈압) =>Diastolic blood pressure (mm Hg)\n",
    "\n",
    "4)SkinThickness (삼두근 피부 두께) =>Triceps skin fold thickness (mm)\n",
    "\n",
    "5)Insulin (2시간 혈청 인슐린) =>2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "6)BMI (체질량지수) =>Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "7)DiabetesPedigreeFunction (당뇨병 혈통 기능) =>Diabetes pedigree function\n",
    "\n",
    "8)Age =>Age (years)\n",
    "\n",
    "9)Outcome =>Class variable (0 or 1) 268 of 768 are 1, the others are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa1114",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 머신러닝 모델들 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43046833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dddadc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 401, 1.0: 213})\n",
      "Resampled dataset shape Counter({0.0: 401, 1.0: 401})\n"
     ]
    }
   ],
   "source": [
    "## diabetes.csv 머신러닝 분류모델  -->  당뇨병 여부 분류\n",
    "\n",
    "# Logistic Regression 이 가장 높은 정확도를 보이고 있습니다.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 데이터 로드\n",
    "url = \"https://github.com/MyungKyuYi/AI-class/raw/main/diabetes.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 0 값을 NaN으로 변환\n",
    "cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI']\n",
    "df[cols] = df[cols].replace(0, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# KNN Imputer 인스턴스 생성, k=5로 설정\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# 결측치 대체를 위해 KNN Imputer 적용\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "# 대체된 데이터를 DataFrame으로 변환하고, 컬럼 이름 재지정\n",
    "df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n",
    "\n",
    "# 특성과 레이블 분리\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA 적용\n",
    "pca = PCA(n_components=2)  # 2차원으로 차원 축소\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    \"SVM\": SVC(kernel='rbf', gamma='scale', probability=True),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 클래스 비율 확인\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#머신러닝 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c230bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0039ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 교차 검증 준비\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# 성능 평가\n",
    "scores = {}\n",
    "for name, model in models.items():\n",
    "    cv_accuracy = cross_val_score(model, X_train_smote, y_train_smote, cv=cv, scoring='accuracy')\n",
    "    cv_f1 = cross_val_score(model, X_train_smote, y_train_smote, cv=cv, scoring='f1')\n",
    "    \n",
    "    scores[name] = {\n",
    "        'Accuracy': np.mean(cv_accuracy),\n",
    "        'F1 Score': np.mean(cv_f1)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceb24c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "SVM: Accuracy = 0.732, F1 Score = 0.753\n",
      "Logistic Regression: Accuracy = 0.733, F1 Score = 0.728\n",
      "Random Forest: Accuracy = 0.758, F1 Score = 0.762\n",
      "Decision Tree: Accuracy = 0.739, F1 Score = 0.734\n",
      "KNN: Accuracy = 0.742, F1 Score = 0.753\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"Cross-validation scores:\")\n",
    "for model, metrics in scores.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['Accuracy']:.3f}, F1 Score = {metrics['F1 Score']:.3f}\")\n",
    "\n",
    "# 그래프로 표시\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(len(models))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "acc_bars = ax.bar(ind - width/2, [scores[name]['Accuracy'] for name in models], width, label='Accuracy')\n",
    "f1_bars = ax.bar(ind + width/2, [scores[name]['F1 Score'] for name in models], width, label='F1 Score')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Accuracy and F1 Score by Model')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(models.keys())\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60583289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 이름: SVM\n",
      "모델: SVC\n",
      "정확도: 0.6948051948051948\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.64      0.73        99\n",
      "         1.0       0.55      0.80      0.65        55\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.70      0.72      0.69       154\n",
      "weighted avg       0.74      0.69      0.70       154\n",
      "\n",
      "------------------------------------------------------------\n",
      "모델 이름: Logistic Regression\n",
      "모델: LogisticRegression\n",
      "정확도: 0.7077922077922078\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.68      0.75        99\n",
      "         1.0       0.57      0.76      0.65        55\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.70      0.72      0.70       154\n",
      "weighted avg       0.74      0.71      0.71       154\n",
      "\n",
      "------------------------------------------------------------\n",
      "모델 이름: Random Forest\n",
      "모델: RandomForestClassifier\n",
      "정확도: 0.6948051948051948\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.73      0.75        99\n",
      "         1.0       0.56      0.64      0.60        55\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.67      0.68      0.68       154\n",
      "weighted avg       0.70      0.69      0.70       154\n",
      "\n",
      "------------------------------------------------------------\n",
      "모델 이름: Decision Tree\n",
      "모델: DecisionTreeClassifier\n",
      "정확도: 0.6493506493506493\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.67      0.71        99\n",
      "         1.0       0.51      0.62      0.56        55\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.63      0.64      0.63       154\n",
      "weighted avg       0.67      0.65      0.66       154\n",
      "\n",
      "------------------------------------------------------------\n",
      "모델 이름: KNN\n",
      "모델: KNeighborsClassifier\n",
      "정확도: 0.6493506493506493\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.65      0.70        99\n",
      "         1.0       0.51      0.65      0.57        55\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.64      0.65      0.64       154\n",
      "weighted avg       0.68      0.65      0.66       154\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 모델 평가를 위한 함수\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)  # 모델 훈련\n",
    "    y_pred = model.predict(X_test)  # 테스트 데이터셋으로 예측\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # 정확도 계산\n",
    "    print(f\"모델: {model.__class__.__name__}\")\n",
    "    print(\"정확도:\", accuracy)\n",
    "    print(\"분류 보고서:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# SMOTE 적용된 데이터를 사용하여 모든 모델 훈련 및 평가\n",
    "for name, model in models.items():\n",
    "    print(f\"모델 이름: {name}\")\n",
    "    evaluate_model(model, X_train_smote, y_train_smote, X_test, y_test)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a21cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오토 인코더 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd92a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2d86fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 401, 1.0: 213})\n",
      "Resampled dataset shape Counter({0.0: 401, 1.0: 401})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 데이터 로드\n",
    "url = \"https://github.com/MyungKyuYi/AI-class/raw/main/diabetes.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 0 값을 NaN으로 변환\n",
    "cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI']\n",
    "df[cols] = df[cols].replace(0, np.nan)\n",
    "\n",
    "\n",
    "# KNN Imputer 인스턴스 생성, k=5로 설정\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# 결측치 대체를 위해 KNN Imputer 적용\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "# 대체된 데이터를 DataFrame으로 변환하고, 컬럼 이름 재지정\n",
    "df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n",
    "\n",
    "# 특성과 레이블 분리\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA 적용\n",
    "pca = PCA(n_components=2)  # 2차원으로 차원 축소\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 클래스 비율 확인\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "752b5c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 2.1331 - val_loss: 2.2871\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0377 - val_loss: 2.1765\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8984 - val_loss: 2.0324\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7788 - val_loss: 1.8682\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6201 - val_loss: 1.7147\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4547 - val_loss: 1.5941\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3852 - val_loss: 1.5077\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3141 - val_loss: 1.4466\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2644 - val_loss: 1.4134\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2408 - val_loss: 1.3977\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2068 - val_loss: 1.3915\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1954 - val_loss: 1.3889\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2000 - val_loss: 1.3884\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2141 - val_loss: 1.3867\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1816 - val_loss: 1.3851\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1961 - val_loss: 1.3839\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2083 - val_loss: 1.3831\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2070 - val_loss: 1.3825\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2219 - val_loss: 1.3818\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1952 - val_loss: 1.3812\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2087 - val_loss: 1.3807\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1806 - val_loss: 1.3805\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2311 - val_loss: 1.3802\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2330 - val_loss: 1.3802\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1971 - val_loss: 1.3802\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2050 - val_loss: 1.3801\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2093 - val_loss: 1.3802\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1710 - val_loss: 1.3801\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1995 - val_loss: 1.3801\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1580 - val_loss: 1.3800\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1860 - val_loss: 1.3799\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2206 - val_loss: 1.3800\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2106 - val_loss: 1.3799\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1973 - val_loss: 1.3800\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2019 - val_loss: 1.3799\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2285 - val_loss: 1.3800\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1803 - val_loss: 1.3799\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2001 - val_loss: 1.3800\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2024 - val_loss: 1.3799\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1780 - val_loss: 1.3798\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1926 - val_loss: 1.3798\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1681 - val_loss: 1.3799\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1779 - val_loss: 1.3799\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1757 - val_loss: 1.3800\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2016 - val_loss: 1.3798\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1548 - val_loss: 1.3799\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1894 - val_loss: 1.3799\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1917 - val_loss: 1.3798\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1861 - val_loss: 1.3800\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2087 - val_loss: 1.3798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21a97905010>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 인코더 부분\n",
    "input_layer = Input(shape=(X_train_smote.shape[1],))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "# 디코더 부분\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(X_train_smote.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "# 오토인코더 모델\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 오토인코더 훈련\n",
    "autoencoder.fit(X_train_smote, X_train_smote,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6664273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "# 인코더 모델\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# 훈련 데이터의 인코딩된 표현\n",
    "encoded_train = encoder.predict(X_train_smote)\n",
    "\n",
    "# 테스트 데이터의 인코딩된 표현\n",
    "encoded_test = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3a1daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6948051948051948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.64      0.73        99\n",
      "         1.0       0.55      0.80      0.65        55\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.70      0.72      0.69       154\n",
      "weighted avg       0.74      0.69      0.70       154\n",
      "\n",
      "Accuracy: 0.6103896103896104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.67      0.69        99\n",
      "         1.0       0.46      0.51      0.48        55\n",
      "\n",
      "    accuracy                           0.61       154\n",
      "   macro avg       0.58      0.59      0.59       154\n",
      "weighted avg       0.62      0.61      0.61       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(encoded_train, y_train_smote)\n",
    "\n",
    "classifier2 = RandomForestClassifier(n_estimators=100)\n",
    "classifier2.fit(encoded_train, y_train_smote)\n",
    "\n",
    "# 성능 평가\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = classifier.predict(encoded_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred2 = classifier2.predict(encoded_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd88a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b34c5e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyeon\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6286 - loss: 0.6667 - val_accuracy: 0.4410 - val_loss: 0.7103\n",
      "Epoch 2/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.5757 - val_accuracy: 0.4596 - val_loss: 0.7792\n",
      "Epoch 3/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7224 - loss: 0.5475 - val_accuracy: 0.5155 - val_loss: 0.6819\n",
      "Epoch 4/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.4968 - val_accuracy: 0.5528 - val_loss: 0.6721\n",
      "Epoch 5/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5091 - val_accuracy: 0.6273 - val_loss: 0.6481\n",
      "Epoch 6/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7131 - loss: 0.5047 - val_accuracy: 0.6770 - val_loss: 0.6113\n",
      "Epoch 7/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7572 - loss: 0.4838 - val_accuracy: 0.5528 - val_loss: 0.6995\n",
      "Epoch 8/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.4787 - val_accuracy: 0.6646 - val_loss: 0.6563\n",
      "Epoch 9/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.4799 - val_accuracy: 0.6273 - val_loss: 0.6885\n",
      "Epoch 10/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7249 - loss: 0.5035 - val_accuracy: 0.6770 - val_loss: 0.6436\n",
      "Epoch 11/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.4875 - val_accuracy: 0.6584 - val_loss: 0.6716\n",
      "Epoch 12/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7486 - loss: 0.4924 - val_accuracy: 0.6894 - val_loss: 0.6540\n",
      "Epoch 13/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7805 - loss: 0.4655 - val_accuracy: 0.6894 - val_loss: 0.6456\n",
      "Epoch 14/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.4767 - val_accuracy: 0.6398 - val_loss: 0.6873\n",
      "Epoch 15/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.4827 - val_accuracy: 0.6832 - val_loss: 0.6694\n",
      "Epoch 16/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.4914 - val_accuracy: 0.7205 - val_loss: 0.6186\n",
      "Epoch 17/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7481 - loss: 0.5030 - val_accuracy: 0.6770 - val_loss: 0.6540\n",
      "Epoch 18/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.4783 - val_accuracy: 0.7205 - val_loss: 0.6161\n",
      "Epoch 19/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.5024 - val_accuracy: 0.6957 - val_loss: 0.6128\n",
      "Epoch 20/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.4614 - val_accuracy: 0.6832 - val_loss: 0.6305\n",
      "Epoch 21/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.5096 - val_accuracy: 0.6957 - val_loss: 0.6262\n",
      "Epoch 22/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.4903 - val_accuracy: 0.6894 - val_loss: 0.6282\n",
      "Epoch 23/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.4901 - val_accuracy: 0.6646 - val_loss: 0.6524\n",
      "Epoch 24/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.4980 - val_accuracy: 0.6770 - val_loss: 0.6420\n",
      "Epoch 25/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.5244 - val_accuracy: 0.6335 - val_loss: 0.7085\n",
      "Epoch 26/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.4793 - val_accuracy: 0.6646 - val_loss: 0.6643\n",
      "Epoch 27/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7709 - loss: 0.4905 - val_accuracy: 0.6708 - val_loss: 0.6391\n",
      "Epoch 28/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.4748 - val_accuracy: 0.5714 - val_loss: 0.6697\n",
      "Epoch 29/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.5030 - val_accuracy: 0.6211 - val_loss: 0.6554\n",
      "Epoch 30/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.4724 - val_accuracy: 0.6832 - val_loss: 0.6064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21a9e1c59d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_smote.shape[1], 1), padding='same'),\n",
    "    MaxPooling1D(pool_size=2, padding='same'),\n",
    "    Conv1D(filters=128, kernel_size=2, activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=2, padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 데이터 형태 조정\n",
    "X_train_scaled_reshaped = X_train_smote.reshape((X_train_smote.shape[0], X_train_smote.shape[1], 1))\n",
    "X_test_scaled_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X_train_scaled_reshaped, y_train_smote, epochs=30, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da1b77b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6830 - loss: 0.5343 \n",
      "CNN Model Accuracy: 0.701298713684082\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test_scaled_reshaped, y_test)\n",
    "print(f\"CNN Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dacd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60768999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MLP 모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f9463c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyeon\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6278 - loss: 0.6334 - val_accuracy: 0.7081 - val_loss: 0.6522\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.4987 - val_accuracy: 0.7143 - val_loss: 0.6767\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.5097 - val_accuracy: 0.6584 - val_loss: 0.6847\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.4869 - val_accuracy: 0.6894 - val_loss: 0.6418\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7641 - loss: 0.4844 - val_accuracy: 0.6211 - val_loss: 0.7207\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7483 - loss: 0.4902 - val_accuracy: 0.6646 - val_loss: 0.6248\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.4944 - val_accuracy: 0.6460 - val_loss: 0.6860\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.4966 - val_accuracy: 0.7267 - val_loss: 0.6125\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.4759 - val_accuracy: 0.6708 - val_loss: 0.6648\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.4762 - val_accuracy: 0.7019 - val_loss: 0.6339\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5145 - val_accuracy: 0.6708 - val_loss: 0.6474\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7473 - loss: 0.4981 - val_accuracy: 0.6957 - val_loss: 0.6396\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.4783 - val_accuracy: 0.6957 - val_loss: 0.6156\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4858 - val_accuracy: 0.6957 - val_loss: 0.6284\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.4902 - val_accuracy: 0.6770 - val_loss: 0.6412\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7433 - loss: 0.5004 - val_accuracy: 0.6894 - val_loss: 0.6249\n",
      "Epoch 17/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 0.4882 - val_accuracy: 0.6894 - val_loss: 0.6622\n",
      "Epoch 18/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7215 - loss: 0.5278 - val_accuracy: 0.7019 - val_loss: 0.6355\n",
      "Epoch 19/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.4693 - val_accuracy: 0.7019 - val_loss: 0.6331\n",
      "Epoch 20/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.4928 - val_accuracy: 0.7205 - val_loss: 0.5715\n",
      "Epoch 21/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7620 - loss: 0.4822 - val_accuracy: 0.7143 - val_loss: 0.6312\n",
      "Epoch 22/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7471 - loss: 0.4909 - val_accuracy: 0.7391 - val_loss: 0.5990\n",
      "Epoch 23/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7462 - loss: 0.4976 - val_accuracy: 0.7578 - val_loss: 0.6104\n",
      "Epoch 24/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.4466 - val_accuracy: 0.7143 - val_loss: 0.6516\n",
      "Epoch 25/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.4708 - val_accuracy: 0.7143 - val_loss: 0.6022\n",
      "Epoch 26/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7631 - loss: 0.4966 - val_accuracy: 0.6832 - val_loss: 0.6390\n",
      "Epoch 27/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.4810 - val_accuracy: 0.7143 - val_loss: 0.5892\n",
      "Epoch 28/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4685 - val_accuracy: 0.7019 - val_loss: 0.6195\n",
      "Epoch 29/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.5096 - val_accuracy: 0.7205 - val_loss: 0.5824\n",
      "Epoch 30/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.4721 - val_accuracy: 0.6335 - val_loss: 0.6611\n",
      "Epoch 31/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.4832 - val_accuracy: 0.7143 - val_loss: 0.5965\n",
      "Epoch 32/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7531 - loss: 0.4968 - val_accuracy: 0.7143 - val_loss: 0.6232\n",
      "Epoch 33/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7584 - loss: 0.4931 - val_accuracy: 0.7081 - val_loss: 0.6184\n",
      "Epoch 34/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7720 - loss: 0.4748 - val_accuracy: 0.7453 - val_loss: 0.5770\n",
      "Epoch 35/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.4740 - val_accuracy: 0.6894 - val_loss: 0.6366\n",
      "Epoch 36/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7545 - loss: 0.4908 - val_accuracy: 0.7267 - val_loss: 0.5851\n",
      "Epoch 37/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.4632 - val_accuracy: 0.7019 - val_loss: 0.6455\n",
      "Epoch 38/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4541 - val_accuracy: 0.7143 - val_loss: 0.6118\n",
      "Epoch 39/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7550 - loss: 0.4751 - val_accuracy: 0.7205 - val_loss: 0.6123\n",
      "Epoch 40/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.4718 - val_accuracy: 0.7453 - val_loss: 0.5971\n",
      "Epoch 41/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.4783 - val_accuracy: 0.7019 - val_loss: 0.6038\n",
      "Epoch 42/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.4863 - val_accuracy: 0.7143 - val_loss: 0.6278\n",
      "Epoch 43/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.4776 - val_accuracy: 0.7019 - val_loss: 0.6274\n",
      "Epoch 44/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7476 - loss: 0.4859 - val_accuracy: 0.7329 - val_loss: 0.5803\n",
      "Epoch 45/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7784 - loss: 0.4622 - val_accuracy: 0.7019 - val_loss: 0.6374\n",
      "Epoch 46/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5098 - val_accuracy: 0.7143 - val_loss: 0.6027\n",
      "Epoch 47/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.4651 - val_accuracy: 0.7019 - val_loss: 0.6109\n",
      "Epoch 48/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5033 - val_accuracy: 0.7205 - val_loss: 0.6025\n",
      "Epoch 49/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.4887 - val_accuracy: 0.6832 - val_loss: 0.6595\n",
      "Epoch 50/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7710 - loss: 0.4886 - val_accuracy: 0.6957 - val_loss: 0.6181\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6734 - loss: 0.5441 \n",
      "MLP Model Accuracy: 0.701298713684082\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_smote.shape[1],)),  # 첫 번째 은닉층\n",
    "    Dropout(0.3),  # 과적합 방지를 위한 드롭아웃\n",
    "    Dense(128, activation='relu'),  # 두 번째 은닉층\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),  # 세 번째 은닉층\n",
    "    Dense(1, activation='sigmoid')  # 출력층\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X_train_smote, y_train_smote, epochs=50, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1ff35b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6734 - loss: 0.5441 \n",
      "MLP Model Accuracy: 0.701298713684082\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"MLP Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc414d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2861082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM --> 포도당을 기준으로 오름차순으로 정렬한 train 데이터를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da258932",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aff79eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 데이터 로드\n",
    "url = \"https://github.com/MyungKyuYi/AI-class/raw/main/diabetes.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 0 값을 NaN으로 변환\n",
    "cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI']\n",
    "df[cols] = df[cols].replace(0, np.nan)\n",
    "\n",
    "# KNN Imputer 인스턴스 생성, k=5로 설정\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# 결측치 대체를 위해 KNN Imputer 적용\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "# 대체된 데이터를 DataFrame으로 변환하고, 컬럼 이름 재지정\n",
    "df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n",
    "# 특성과 레이블 분리\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링 (옵션)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# SMOTE 적용된 데이터를 데이터프레임으로 변환\n",
    "columns = X_train.columns  # 원래 데이터의 컬럼명 사용\n",
    "X_train_smote_df = pd.DataFrame(X_train_smote, columns=columns)\n",
    "X_train_smote_df['Outcome'] = y_train_smote  # 레이블 컬럼 추가\n",
    "\n",
    "# 포도당('Glucose')을 기준으로 데이터 정렬\n",
    "sorted_df = X_train_smote_df.sort_values(by='Glucose', ascending=True)\n",
    "\n",
    "# 정렬된 데이터에서 X 및 y 추출\n",
    "X_sorted = sorted_df.drop('Outcome', axis=1)\n",
    "y_sorted = sorted_df['Outcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afc0c784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyeon\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6225 - loss: 0.6875 - val_accuracy: 0.7329 - val_loss: 0.6801\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6640 - loss: 0.6627 - val_accuracy: 0.7950 - val_loss: 0.6526\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6818 - loss: 0.6154 - val_accuracy: 0.8075 - val_loss: 0.6133\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7089 - loss: 0.5540 - val_accuracy: 0.8385 - val_loss: 0.5731\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.5420 - val_accuracy: 0.8447 - val_loss: 0.5420\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.5147 - val_accuracy: 0.8261 - val_loss: 0.5084\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.4810 - val_accuracy: 0.8199 - val_loss: 0.4841\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.5168 - val_accuracy: 0.8385 - val_loss: 0.4703\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.5017 - val_accuracy: 0.8571 - val_loss: 0.4538\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4701 - val_accuracy: 0.8571 - val_loss: 0.4485\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.4733 - val_accuracy: 0.8571 - val_loss: 0.4473\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7601 - loss: 0.4760 - val_accuracy: 0.8634 - val_loss: 0.4338\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.4824 - val_accuracy: 0.8696 - val_loss: 0.4267\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.4942 - val_accuracy: 0.8696 - val_loss: 0.4241\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.4985 - val_accuracy: 0.8758 - val_loss: 0.4183\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.4931 - val_accuracy: 0.8820 - val_loss: 0.4147\n",
      "Epoch 17/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7462 - loss: 0.4991 - val_accuracy: 0.8820 - val_loss: 0.4081\n",
      "Epoch 18/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7575 - loss: 0.4840 - val_accuracy: 0.8820 - val_loss: 0.4059\n",
      "Epoch 19/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.4515 - val_accuracy: 0.8758 - val_loss: 0.4033\n",
      "Epoch 20/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.4631 - val_accuracy: 0.8758 - val_loss: 0.4011\n",
      "Epoch 21/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4368 - val_accuracy: 0.8820 - val_loss: 0.4017\n",
      "Epoch 22/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.4629 - val_accuracy: 0.8820 - val_loss: 0.3947\n",
      "Epoch 23/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.4617 - val_accuracy: 0.8758 - val_loss: 0.3897\n",
      "Epoch 24/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4504 - val_accuracy: 0.8696 - val_loss: 0.4019\n",
      "Epoch 25/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4663 - val_accuracy: 0.8758 - val_loss: 0.3993\n",
      "Epoch 26/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.4676 - val_accuracy: 0.8696 - val_loss: 0.4005\n",
      "Epoch 27/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4160 - val_accuracy: 0.8696 - val_loss: 0.4096\n",
      "Epoch 28/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4559 - val_accuracy: 0.8820 - val_loss: 0.4104\n",
      "Epoch 29/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4240 - val_accuracy: 0.8634 - val_loss: 0.4227\n",
      "Epoch 30/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.4595 - val_accuracy: 0.8758 - val_loss: 0.4119\n",
      "Epoch 31/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.4443 - val_accuracy: 0.8882 - val_loss: 0.3964\n",
      "Epoch 32/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7737 - loss: 0.4522 - val_accuracy: 0.8820 - val_loss: 0.3872\n",
      "Epoch 33/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4300 - val_accuracy: 0.8820 - val_loss: 0.3801\n",
      "Epoch 34/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.4443 - val_accuracy: 0.8758 - val_loss: 0.3792\n",
      "Epoch 35/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4254 - val_accuracy: 0.8758 - val_loss: 0.3786\n",
      "Epoch 36/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4392 - val_accuracy: 0.8634 - val_loss: 0.3916\n",
      "Epoch 37/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.4357 - val_accuracy: 0.8696 - val_loss: 0.3889\n",
      "Epoch 38/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7860 - loss: 0.4292 - val_accuracy: 0.8571 - val_loss: 0.3910\n",
      "Epoch 39/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4233 - val_accuracy: 0.8385 - val_loss: 0.4177\n",
      "Epoch 40/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7854 - loss: 0.4244 - val_accuracy: 0.8385 - val_loss: 0.4179\n",
      "Epoch 41/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4350 - val_accuracy: 0.8385 - val_loss: 0.4166\n",
      "Epoch 42/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.4035 - val_accuracy: 0.8323 - val_loss: 0.4315\n",
      "Epoch 43/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8140 - loss: 0.4048 - val_accuracy: 0.8323 - val_loss: 0.4215\n",
      "Epoch 44/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4038 - val_accuracy: 0.8199 - val_loss: 0.4368\n",
      "Epoch 45/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.4190 - val_accuracy: 0.8199 - val_loss: 0.4285\n",
      "Epoch 46/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.4325 - val_accuracy: 0.8199 - val_loss: 0.4304\n",
      "Epoch 47/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4328 - val_accuracy: 0.8261 - val_loss: 0.4220\n",
      "Epoch 48/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.4229 - val_accuracy: 0.8323 - val_loss: 0.4140\n",
      "Epoch 49/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.3923 - val_accuracy: 0.8323 - val_loss: 0.4130\n",
      "Epoch 50/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4384 - val_accuracy: 0.8261 - val_loss: 0.4171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21aa5f60590>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 데이터 형태 조정\n",
    "# RNN은 (samples, timesteps, features) 형태의 입력을 필요로 함\n",
    "X_train_rnn = X_sorted.values.reshape((X_sorted.shape[0], 1, X_sorted.shape[1]))\n",
    "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X_train_rnn, y_sorted, epochs=50, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1d772ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7120 - loss: 0.6261 \n",
      "LSTM Model Accuracy: 0.7272727489471436\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test_rnn, y_test)\n",
    "print(f\"LSTM Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576295fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f310101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
